{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99 / 100 (266)\n",
      "78 unique peptides. 101 total\n"
     ]
    }
   ],
   "source": [
    "protein = \"MAHVRGLQLPGCLALAALCSLVHSQHVFLAPQQARSLLQRVRRANTFLEEVRKGNLERECVEETCSYEEAFEALESSTATDVFWAKYTACETARTPRDKLAACLEGNCAEGLGTNYRGHVNITRSGIECQLWRSRYPHKPEINSTTHPGADLQENFCRNPDSSTTGPWCYTTDPTVRRQECSIPVCGQDQVTVAMTPRSEGSSVNLSPPLEQCVPDRGQQYQGRLAVTTHGLPCLAWASAQAKALSKHQDFNSAVQLVENFCRNPDGDEEGVWCYVAGKPGDFGYCDLNYCEEAVEEETGDGLDEDSDRAIEGRTATSEYQTFFNPRTFGSGEADCGLRPLFEKKSLEDKTERELLESYIDGRIVEGSDAEIGMSPWQVMLFRKSPQELLCGASLISDRWVLTAAHCLLYPPWDKNFTENDLLVRIGKHSRTRYERNIEKISMLEKIYIHPRYNWRENLDRDIALMKLKKPVAFSDYIHPVCLPDRETAASLLQAGYKGRVTGWGNLKETWTANVGKGQPSVLQVVNLPIVERPVCKDSTRIRITDNMFCAGYKPDEGKRGDACEGDSGGPFVMKSPFNNRWYQMGIVSWGEGCDRDGKYGFYTHVFRLKKWIQKVIDQFGE\"\n",
    "from disassembly.simulate_proteolysis import simulate_proteolysis, enzyme_set, enzyme\n",
    "\n",
    "enzymes = enzyme_set(\n",
    "    [\n",
    "        enzyme({\"K\": 1}, \"protease_iv\"),\n",
    "        enzyme({\"K\": 0.5, \"R\": 0.5}, \"trypsin\"),\n",
    "        enzyme({\"V\": 0.5, \"I\": 0.25, \"A\": 0.15, \"T\": 0.1}, \"elne\"),\n",
    "    ],\n",
    "    [1, 1, 0],  # activities\n",
    "    [1, 1, 0],  # abundances\n",
    ")\n",
    "\n",
    "\n",
    "P, sequence_graph = simulate_proteolysis(\n",
    "    protein,\n",
    "    n_start=1,\n",
    "    n_generate=100,\n",
    "    endo_or_exo_probability=[0.9, 0.1],\n",
    "    enzymes=enzymes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate descent\n",
    "\n",
    "\n",
    "\n",
    "```py\n",
    "\n",
    "G = #graph with weights\n",
    "\n",
    "#Sort weights so that we start from the outgoing weights from largest nodes (\"to the left\").\n",
    "\n",
    "for i in range(n_iterations): \n",
    "    for w in weights:   \n",
    "        grad = compute_dL_dw() # compute gradient dependent on w\n",
    "        w = w - grad * lr * k #update weight, make sure that sum(weights from outgoing node) < 1\n",
    "        \n",
    "\n",
    "        \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-paramterization\n",
    "\n",
    "We parameterize\n",
    "\n",
    "$w(\\theta)$ where $\\theta$ is constant for amino-acids and exoprotease\n",
    "\n",
    "theta = {\"A\":a, \"B\": b ..., \"exo\":exo} where \"A\" and \"B\" are p1-amino-acids.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from disassembly.util import KL, amino_acids\n",
    "\n",
    "\n",
    "class WeightEstimatorGD:\n",
    "    \"\"\"\n",
    "    Class to estimate weights using gradient descent.\n",
    "\n",
    "    ```\n",
    "    wegd = WeightEstimatorGD(lr, n_iterations, lam)\n",
    "    generated_graph = wegd(true_dict, verbose=True)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        n_iterations: int,\n",
    "        lam: float,\n",
    "    ) -> None:\n",
    "        self.lr = lr\n",
    "        self.n_iterations = n_iterations\n",
    "        self.lam = lam\n",
    "\n",
    "    def run(self, true_dict: dict, verbose: bool):\n",
    "        self.parameters = {\n",
    "            \"endo\": {aa: 0.75 for aa in amino_acids.values()},\n",
    "            \"exo\": 0.75,\n",
    "            \"stop\": 0.25,\n",
    "        }  # endo is dict of aa at p1\n",
    "\n",
    "        self.true_dict = true_dict\n",
    "        self.keys = list(true_dict.keys())\n",
    "        self.true_dict_vals = list(true_dict.values())\n",
    "        self.graph = self.create_graph()  # creates the graph from keys\n",
    "\n",
    "        self.generated = {}\n",
    "        self.losses = []\n",
    "        self.weights = {}\n",
    "\n",
    "        for iteration in range(self.n_iterations):\n",
    "            guess, guess_df = self.generate_output(self.graph)\n",
    "            self.generated[iteration] = guess\n",
    "            self.weights[iteration] = np.array(\n",
    "                [data[\"weight\"] for _, _, data in self.graph.edges(data=True)]\n",
    "            )\n",
    "            # Compute loss\n",
    "            kl = KL(self.true_dict_vals, guess.values())\n",
    "            reg = get_l2(self.graph) * self.lam\n",
    "            loss = kl + reg\n",
    "            self.losses.append(loss)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"\\r {iteration} / {self.n_iterations} | {loss:.2f}, kl: {kl:.2f}, reg: {reg:.2f}  | nz: { np.sum( self.weights[iteration] > 0.01 )} | \",\n",
    "                    end=\"\",\n",
    "                    flush=True,\n",
    "                )\n",
    "\n",
    "            # Compute gradient\n",
    "            dp_dw = self.compute_dp_dw(guess_df)\n",
    "            dL_dp = self.compute_dL_dp(self.true_dict_vals, list(guess.values()))\n",
    "            gradient = self.compute_dL_dw(dL_dp, dp_dw)\n",
    "            grad_reg = self.get_grad_reg_l2(self.graph)\n",
    "\n",
    "            # Update graph\n",
    "            self.graph = self.update_weights(gradient, grad_reg)\n",
    "\n",
    "            if loss < 0.01:\n",
    "                break\n",
    "\n",
    "        return self.graph\n",
    "\n",
    "    def generate_output(self, graph: nx.DiGraph) -> (dict, pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generates an output dict from a graph\n",
    "        \"\"\"\n",
    "        longest_key = sorted(self.keys, key=len)[-1]\n",
    "        p_generated = {}\n",
    "        terminal_nodes = [node for node in graph.nodes() if graph.out_degree(node) == 0]\n",
    "\n",
    "        for node in terminal_nodes:  # one hot terminal nodes\n",
    "            oh_node = create_one_hot(self.keys, node)\n",
    "            p_generated[node] = oh_node\n",
    "\n",
    "        out_edges = {\n",
    "            source: [\n",
    "                target for _, target in graph.out_edges(source) if source != target\n",
    "            ]\n",
    "            for source in graph.nodes()\n",
    "        }\n",
    "\n",
    "        while len(p_generated.keys()) < len(self.keys):\n",
    "            solvables = get_solvable(out_edges, p_generated)\n",
    "            for solvable in solvables:\n",
    "                p_generated[solvable] = np.zeros(len(self.keys))\n",
    "\n",
    "                for source, target in graph.out_edges(solvable):\n",
    "                    p_target = p_generated[target]\n",
    "                    w_source_target = graph[source][target][\"weight\"]\n",
    "                    p_generated[source] += w_source_target * p_target\n",
    "\n",
    "                w_source_target = 1 - sum(\n",
    "                    [\n",
    "                        data[\"weight\"]\n",
    "                        for _, _, data in graph.out_edges(source, data=True)\n",
    "                    ]\n",
    "                )\n",
    "                p_target = create_one_hot(self.keys, source)\n",
    "                p_generated[source] += w_source_target * p_target\n",
    "\n",
    "        guess = {\n",
    "            self.keys[i]: p_generated[longest_key][i] for i in range(len(self.keys))\n",
    "        }\n",
    "        return guess, pd.DataFrame(p_generated, index=self.keys)\n",
    "\n",
    "    def create_graph(self):\n",
    "        \"\"\"\n",
    "        Each edge has a weight, a type and a p1_left and p1_right\n",
    "\n",
    "        p1_left exists if there has been a cut on the left of the generated peptide\n",
    "        p1_right ---ll---\n",
    "\n",
    "        type is endo or exo\n",
    "\n",
    "        \"\"\"\n",
    "        graph = nx.DiGraph()\n",
    "        graph.add_nodes_from([(k, {\"layer\": len(k)}) for k in self.keys])\n",
    "        for key1 in self.keys:\n",
    "            for key2 in self.keys:\n",
    "                if (key1 in key2) and (key1 != key2):\n",
    "                    if len(key1) == len(key2) - 1:\n",
    "                        endo_or_exo = \"exo\"\n",
    "                        p1_left = None\n",
    "                        p1_right = None\n",
    "                        w = self.parameters[\"exo\"]\n",
    "                    elif key2.startswith(key1):\n",
    "                        endo_or_exo = \"endo\"\n",
    "                        p1_left = None\n",
    "                        p1_right = key1[-1]\n",
    "                        w = self.parameters[\"endo\"][p1_right]\n",
    "                    elif key2.endswith(key1):\n",
    "                        endo_or_exo = \"endo\"\n",
    "                        p1_left = key2[-len(key1) - 1]\n",
    "                        p1_right = None\n",
    "                        w = self.parameters[\"endo\"][p1_left]\n",
    "                    else:  # middle\n",
    "                        endo_or_exo = \"endo\"\n",
    "                        p1_left = key2[key2.find(key1) - 1]\n",
    "                        p1_right = key1[-1]\n",
    "                        w = (\n",
    "                            self.parameters[\"endo\"][p1_left]\n",
    "                            * self.parameters[\"endo\"][p1_right]\n",
    "                        )\n",
    "\n",
    "                    graph.add_edge(\n",
    "                        key2,\n",
    "                        key1,\n",
    "                        weight=w,\n",
    "                        type=endo_or_exo,\n",
    "                        p1_left=p1_left,\n",
    "                        p1_right=p1_right,\n",
    "                    )\n",
    "\n",
    "        return graph\n",
    "\n",
    "    def update_weights_w_parameters(self):\n",
    "        \"\"\"\n",
    "\n",
    "        Updates the graph weights based on self.parameters\n",
    "\n",
    "        \"\"\"\n",
    "        new_graph = self.graph.copy()\n",
    "\n",
    "        for source, target, data in new_graph.edges(data=True):\n",
    "            if data[\"type\"] == \"exo\":\n",
    "                w = self.parameters[\"exo\"]\n",
    "            elif data[\"type\"] == \"endo\":\n",
    "                if data[\"p1_left\"] is None:\n",
    "                    w = self.parameters[\"endo\"][data[\"p1_right\"]]\n",
    "                elif data[\"p1_right\"] is None:\n",
    "                    w = self.parameters[\"endo\"][data[\"p1_left\"]]\n",
    "                else:\n",
    "                    w = (\n",
    "                        self.parameters[\"endo\"][data[\"p1_left\"]]\n",
    "                        * self.parameters[\"endo\"][data[\"p1_right\"]]\n",
    "                    )\n",
    "            nx.set_edge_attributes(\n",
    "                new_graph,\n",
    "                {\n",
    "                    (source, target): {\n",
    "                        \"weight\": w\n",
    "                    }\n",
    "                },\n",
    "            )\n",
    "        return new_graph\n",
    "\n",
    "    def compute_dp_dw(self, guess_df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        dP / dw\n",
    "        Change of P based on w\n",
    "        Sx1 vector\n",
    "        \"\"\"\n",
    "        longest_key = sorted(self.keys, key=len)[-1]\n",
    "        prob_traversed = {key: 0 for key in self.keys}\n",
    "        prob_traversed[longest_key] = 1\n",
    "\n",
    "        for sequence, n in prob_traversed.items():\n",
    "            out_edges = [\n",
    "                (source, target, data)\n",
    "                for source, target, data in self.graph.out_edges(sequence, data=True)\n",
    "            ]\n",
    "            weights = np.array([weight[\"weight\"] for _, _, weight in out_edges])\n",
    "            edges_to = [edge_to for _, edge_to, _ in out_edges]\n",
    "            for w, e in zip(weights, edges_to):\n",
    "                prob_traversed[e] += w * n\n",
    "\n",
    "        dp_dw = {}\n",
    "\n",
    "        for key in self.keys:\n",
    "            out_edges = self.graph.out_edges(key)\n",
    "            for (\n",
    "                source,\n",
    "                target,\n",
    "            ) in out_edges:  # P(longest to source) * (P(target) - onehot(source))\n",
    "                dp_dw[(source, target)] = prob_traversed[source] * (\n",
    "                    guess_df[target].values - create_one_hot(self.keys, source)\n",
    "                )\n",
    "\n",
    "        return dp_dw\n",
    "\n",
    "    def update_weights(self, grad, grad_reg=None) -> nx.DiGraph:\n",
    "        diffs = {}\n",
    "        k = 1\n",
    "\n",
    "        old_graph = nx.DiGraph()\n",
    "        for source, target, data in self.graph.edges(data=True):\n",
    "            old_graph.add_edge(source, target, weight=data[\"weight\"])\n",
    "\n",
    "        old_loss = self.losses[-1]\n",
    "\n",
    "        for source in self.graph.nodes():\n",
    "            sum_old_weight = sum(\n",
    "                [\n",
    "                    data[\"weight\"]\n",
    "                    for _, _, data in self.graph.out_edges(source, data=True)\n",
    "                ]\n",
    "            )\n",
    "            sum_diffs = 0\n",
    "\n",
    "            for source, target in self.graph.out_edges(source):\n",
    "                old_weight = self.graph[source][target][\"weight\"]\n",
    "                grad_weight = grad[(source, target)]\n",
    "\n",
    "                if grad_reg:  # if we regularize\n",
    "                    grad_weight += grad_reg[(source, target)]\n",
    "\n",
    "                new_weight = max(0, old_weight - self.lr * grad_weight)\n",
    "                diff = new_weight - old_weight  # diff is -lr*grad\n",
    "                sum_diffs += diff\n",
    "                diffs[(source, target)] = diff\n",
    "\n",
    "            while (sum_old_weight + k * sum_diffs) >= 1:\n",
    "                k = k / 2\n",
    "\n",
    "        new_graph = self.graph.copy()\n",
    "\n",
    "        while True:\n",
    "            # Update graph\n",
    "            for source, target in new_graph.edges():\n",
    "                nx.set_edge_attributes(\n",
    "                    new_graph,\n",
    "                    {\n",
    "                        (source, target): {\n",
    "                            \"weight\": max(\n",
    "                                0,\n",
    "                                old_graph[source][target][\"weight\"]\n",
    "                                + diffs[(source, target)] * k,\n",
    "                            )\n",
    "                        }\n",
    "                    },\n",
    "                )\n",
    "\n",
    "            # Get new KL\n",
    "            new_guess, _ = self.generate_output(new_graph)\n",
    "\n",
    "            new_loss = KL(self.true_dict_vals, list(new_guess.values())) + (\n",
    "                get_l2(new_graph) * self.lam\n",
    "            )\n",
    "\n",
    "            if new_loss <= old_loss:\n",
    "                return new_graph\n",
    "\n",
    "            if k < 1e-15:\n",
    "                return old_graph\n",
    "\n",
    "            k = k / 2\n",
    "            new_graph = self.graph  # resets the new_graph to graph\n",
    "\n",
    "\n",
    "    def update_parameters(self, dL_dtheta):\n",
    "        \"\"\"\n",
    "\n",
    "        Update the parameters with dL_dtheta\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def compute_dL_dp(self, true, guess):\n",
    "        return -np.array(true) / (np.array(guess) + 1e-8)\n",
    "\n",
    "    def compute_dL_dw(self, dL_dp, dp_dw):\n",
    "        \"\"\"\n",
    "        Gradient\n",
    "        \"\"\"\n",
    "        dL_dw = {}\n",
    "        for edge, val in dp_dw.items():\n",
    "            dL_dw[edge] = np.sum(val * dL_dp)\n",
    "        return dL_dw\n",
    "\n",
    "    def get_grad_reg_l2(self, graph):\n",
    "        grad_reg = {}\n",
    "        for source in graph.nodes():\n",
    "            for _, target, data in graph.out_edges(source, data=True):\n",
    "                grad_reg[(source, target)] = 2 * data[\"weight\"] * self.lam  # + self.lam\n",
    "        return grad_reg\n",
    "\n",
    "    def drop_weights(self, threshold: float = 0.01):\n",
    "        \"\"\"\n",
    "        Idea, drop edges that are very small\n",
    "        \"\"\"\n",
    "        new_graph = nx.DiGraph()\n",
    "        for source, target, data in self.graph.edges(data=True):\n",
    "            if data[\"weight\"] > threshold:\n",
    "                new_graph.add_edge(source, target, weight=data[\"weight\"])\n",
    "        return new_graph\n",
    "\n",
    "    def dw_dtheta(self):\n",
    "        \"gradient of theta\"\n",
    "        dw_dtheta = {\n",
    "            \"endo\": 1 - self.parameters[\"stop\"],\n",
    "            \"exo\": 1 - self.parameters[\"stop\"],\n",
    "            \"stop\": 0,\n",
    "        }\n",
    "        return dw_dtheta\n",
    "\n",
    "    def compute_dL_dtheta(self, dL_dw, dw_dtheta):\n",
    "        \"\"\"\n",
    "        dL/dtheta = dL/dw * dw/dtheta\n",
    "        \"\"\"\n",
    "        dL_dtheta = {}\n",
    "        for edge, val in dL_dw.items():\n",
    "            data = self.graph[edge]\n",
    "            dL_dtheta[edge] = val * dw_dtheta[data[\"type\"]]  # 1x1 * 1x1\n",
    "\n",
    "        return dL_dtheta\n",
    "\n",
    "\n",
    "def create_one_hot(keys, key):\n",
    "    one_hot = np.zeros(len(keys))\n",
    "    one_hot[keys.index(key)] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def get_solvable(out_edges, p_generated):\n",
    "    solvable = []\n",
    "    for source, targets in out_edges.items():\n",
    "        if (\n",
    "            set(targets).issubset(set((p_generated.keys())))\n",
    "            and source not in p_generated.keys()\n",
    "        ):\n",
    "            solvable.append(source)\n",
    "    return solvable\n",
    "\n",
    "\n",
    "def get_l1(graph):\n",
    "    return sum([abs(data[\"weight\"]) for _, _, data in graph.edges(data=True)])\n",
    "\n",
    "\n",
    "def get_l2(graph):\n",
    "    return sum([data[\"weight\"] ** 2 for _, _, data in graph.edges(data=True)])\n",
    "\n",
    "\n",
    "def get_elastic_net(graph, lambda_1, lambda_2):\n",
    "    return sum(\n",
    "        [\n",
    "            (lambda_1 * abs(data[\"weight\"]))  # L1\n",
    "            + (lambda_2 * data[\"weight\"] ** 2)  # L2\n",
    "            for _, _, data in graph.edges(data=True)\n",
    "        ]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
