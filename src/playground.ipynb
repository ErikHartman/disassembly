{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99 / 100 (266)\n",
      "78 unique peptides. 101 total\n"
     ]
    }
   ],
   "source": [
    "protein = \"MAHVRGLQLPGCLALAALCSLVHSQHVFLAPQQARSLLQRVRRANTFLEEVRKGNLERECVEETCSYEEAFEALESSTATDVFWAKYTACETARTPRDKLAACLEGNCAEGLGTNYRGHVNITRSGIECQLWRSRYPHKPEINSTTHPGADLQENFCRNPDSSTTGPWCYTTDPTVRRQECSIPVCGQDQVTVAMTPRSEGSSVNLSPPLEQCVPDRGQQYQGRLAVTTHGLPCLAWASAQAKALSKHQDFNSAVQLVENFCRNPDGDEEGVWCYVAGKPGDFGYCDLNYCEEAVEEETGDGLDEDSDRAIEGRTATSEYQTFFNPRTFGSGEADCGLRPLFEKKSLEDKTERELLESYIDGRIVEGSDAEIGMSPWQVMLFRKSPQELLCGASLISDRWVLTAAHCLLYPPWDKNFTENDLLVRIGKHSRTRYERNIEKISMLEKIYIHPRYNWRENLDRDIALMKLKKPVAFSDYIHPVCLPDRETAASLLQAGYKGRVTGWGNLKETWTANVGKGQPSVLQVVNLPIVERPVCKDSTRIRITDNMFCAGYKPDEGKRGDACEGDSGGPFVMKSPFNNRWYQMGIVSWGEGCDRDGKYGFYTHVFRLKKWIQKVIDQFGE\"\n",
    "from disassembly.simulate_proteolysis import simulate_proteolysis, enzyme_set, enzyme\n",
    "\n",
    "enzymes = enzyme_set(\n",
    "    [\n",
    "        enzyme({\"K\": 1}, \"protease_iv\"),\n",
    "        enzyme({\"K\": 0.5, \"R\": 0.5}, \"trypsin\"),\n",
    "        enzyme({\"V\": 0.5, \"I\": 0.25, \"A\": 0.15, \"T\": 0.1}, \"elne\"),\n",
    "    ],\n",
    "    [1, 1, 0],  # activities\n",
    "    [1, 1, 0],  # abundances\n",
    ")\n",
    "\n",
    "\n",
    "P, sequence_graph = simulate_proteolysis(\n",
    "    protein,\n",
    "    n_start=1,\n",
    "    n_generate=100,\n",
    "    endo_or_exo_probability=[0.9, 0.1],\n",
    "    enzymes=enzymes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate descent\n",
    "\n",
    "\n",
    "\n",
    "```py\n",
    "\n",
    "G = #graph with weights\n",
    "\n",
    "#Sort weights so that we start from the outgoing weights from largest nodes (\"to the left\").\n",
    "\n",
    "for i in range(n_iterations): \n",
    "    for w in weights:   \n",
    "        grad = compute_dL_dw() # compute gradient dependent on w\n",
    "        w = w - grad * lr * k #update weight, make sure that sum(weights from outgoing node) < 1\n",
    "        \n",
    "\n",
    "        \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-paramterization\n",
    "\n",
    "We parameterize\n",
    "\n",
    "$w(\\theta)$ where $\\theta$ is constant for amino-acids and exoprotease\n",
    "\n",
    "theta = {\"A\":a, \"B\": b ..., \"exo\":exo} where \"A\" and \"B\" are p1-amino-acids.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from disassembly.util import KL, amino_acids\n",
    "\n",
    "\n",
    "class WeightEstimatorGD:\n",
    "    \"\"\"\n",
    "    Class to estimate weights using gradient descent.\n",
    "\n",
    "    ```\n",
    "    wegd = WeightEstimatorGD(lr, n_iterations, lam)\n",
    "    generated_graph = wegd(true_dict, verbose=True)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        n_iterations: int,\n",
    "        lam: float,\n",
    "    ) -> None:\n",
    "        self.lr = lr\n",
    "        self.n_iterations = n_iterations\n",
    "        self.lam = lam\n",
    "\n",
    "    def run(self, true_dict: dict, verbose: bool):\n",
    "        exo = 0.1\n",
    "        self.parameters = {\n",
    "            \"endo\": {\n",
    "                aa: 1 / (len(amino_acids.values()) + exo) for aa in amino_acids.values()\n",
    "            },\n",
    "            \"exo\": exo,\n",
    "            \"stop\": 0.25,\n",
    "        }  # endo is dict of aa at p1\n",
    "\n",
    "        self.true_dict = true_dict\n",
    "        self.keys = list(true_dict.keys())\n",
    "        self.true_dict_vals = list(true_dict.values())\n",
    "        self.graph = self.create_graph()  # creates the graph from keys\n",
    "\n",
    "        self.generated = {}\n",
    "        self.losses = []\n",
    "        self.weights = {}\n",
    "\n",
    "        for iteration in range(self.n_iterations):\n",
    "            guess, guess_df = self.generate_output(self.graph)\n",
    "            self.generated[iteration] = guess\n",
    "            self.weights[iteration] = np.array(\n",
    "                [data[\"weight\"] for _, _, data in self.graph.edges(data=True)]\n",
    "            )\n",
    "            # Compute loss\n",
    "            kl = KL(self.true_dict_vals, guess.values())\n",
    "            reg = get_l2(self.graph) * self.lam\n",
    "            loss = kl + reg\n",
    "            self.losses.append(loss)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"\\r {iteration} / {self.n_iterations} | {loss:.2f}, kl: {kl:.2f}, reg: {reg:.2f}  | nz: { np.sum( self.weights[iteration] > 0.01 )} | \",\n",
    "                    end=\"\",\n",
    "                    flush=True,\n",
    "                )\n",
    "\n",
    "            # Compute gradient\n",
    "            dp_dw = self.compute_dp_dw(guess_df)\n",
    "            dL_dp = self.compute_dL_dp(self.true_dict_vals, list(guess.values()))\n",
    "            gradient = self.compute_dL_dw(dL_dp, dp_dw)\n",
    "            grad_reg = self.get_grad_reg_l2(self.graph)\n",
    "\n",
    "            # Update graph\n",
    "            self.graph = self.update_weights(gradient, grad_reg)\n",
    "\n",
    "            if loss < 0.01:\n",
    "                break\n",
    "\n",
    "        return self.graph\n",
    "\n",
    "    def generate_output(self, graph: nx.DiGraph) -> (dict, pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generates an output dict from a graph\n",
    "        \"\"\"\n",
    "        longest_key = sorted(self.keys, key=len)[-1]\n",
    "        p_generated = {}\n",
    "        terminal_nodes = [node for node in graph.nodes() if graph.out_degree(node) == 0]\n",
    "\n",
    "        for node in terminal_nodes:  # one hot terminal nodes\n",
    "            oh_node = create_one_hot(self.keys, node)\n",
    "            p_generated[node] = oh_node\n",
    "\n",
    "        out_edges = {\n",
    "            source: [\n",
    "                target for _, target in graph.out_edges(source) if source != target\n",
    "            ]\n",
    "            for source in graph.nodes()\n",
    "        }\n",
    "\n",
    "        while len(p_generated.keys()) < len(self.keys):\n",
    "            solvables = get_solvable(out_edges, p_generated)\n",
    "            for solvable in solvables:\n",
    "                p_generated[solvable] = np.zeros(len(self.keys))\n",
    "\n",
    "                for source, target in graph.out_edges(solvable):\n",
    "                    p_target = p_generated[target]\n",
    "                    w_source_target = graph[source][target][\"weight\"]\n",
    "                    p_generated[source] += w_source_target * p_target\n",
    "\n",
    "                w_source_target = 1 - sum(\n",
    "                    [\n",
    "                        data[\"weight\"]\n",
    "                        for _, _, data in graph.out_edges(source, data=True)\n",
    "                    ]\n",
    "                )\n",
    "                p_target = create_one_hot(self.keys, source)\n",
    "                p_generated[source] += w_source_target * p_target\n",
    "\n",
    "        guess = {\n",
    "            self.keys[i]: p_generated[longest_key][i] for i in range(len(self.keys))\n",
    "        }\n",
    "        return guess, pd.DataFrame(p_generated, index=self.keys)\n",
    "\n",
    "    def create_graph(self):\n",
    "        \"\"\"\n",
    "        Each edge has a weight, a type and a p1_left and p1_right\n",
    "\n",
    "        p1_left exists if there has been a cut on the left of the generated peptide\n",
    "        p1_right ---ll---\n",
    "\n",
    "        type is endo or exo\n",
    "\n",
    "        \"\"\"\n",
    "        graph = nx.DiGraph()\n",
    "        graph.add_nodes_from([(k, {\"layer\": len(k)}) for k in self.keys])\n",
    "        for key1 in self.keys:\n",
    "            for key2 in self.keys:\n",
    "                if (key1 in key2) and (key1 != key2):\n",
    "                    if len(key1) == len(key2) - 1:\n",
    "                        endo_or_exo = \"exo\"\n",
    "                        p1_left = None\n",
    "                        p1_right = None\n",
    "                        w = self.parameters[\"exo\"]\n",
    "                    elif key2.startswith(key1):\n",
    "                        endo_or_exo = \"endo\"\n",
    "                        p1_left = None\n",
    "                        p1_right = key1[-1]\n",
    "                        w = self.parameters[\"endo\"][p1_right]\n",
    "                    elif key2.endswith(key1):\n",
    "                        endo_or_exo = \"endo\"\n",
    "                        p1_left = key2[-len(key1) - 1]\n",
    "                        p1_right = None\n",
    "                        w = self.parameters[\"endo\"][p1_left]\n",
    "                    else:  # middle\n",
    "                        endo_or_exo = \"endo\"\n",
    "                        p1_left = key2[key2.find(key1) - 1]\n",
    "                        p1_right = key1[-1]\n",
    "                        w = (\n",
    "                            self.parameters[\"endo\"][p1_left]\n",
    "                            * self.parameters[\"endo\"][p1_right]\n",
    "                        )\n",
    "\n",
    "                    graph.add_edge(\n",
    "                        key2,\n",
    "                        key1,\n",
    "                        weight=w,\n",
    "                        type=endo_or_exo,\n",
    "                        p1_left=p1_left,\n",
    "                        p1_right=p1_right,\n",
    "                    )\n",
    "\n",
    "        return graph\n",
    "\n",
    "    def update_weights_w_parameters(self):\n",
    "        \"\"\"\n",
    "\n",
    "        Updates the graph weights based on self.parameters\n",
    "\n",
    "        \"\"\"\n",
    "        new_graph = self.graph.copy()\n",
    "\n",
    "        for source, target, data in new_graph.edges(data=True):\n",
    "            if data[\"type\"] == \"exo\":\n",
    "                w = self.parameters[\"exo\"]\n",
    "            elif data[\"type\"] == \"endo\":\n",
    "                if data[\"p1_left\"] is None:\n",
    "                    w = self.parameters[\"endo\"][data[\"p1_right\"]]\n",
    "                elif data[\"p1_right\"] is None:\n",
    "                    w = self.parameters[\"endo\"][data[\"p1_left\"]]\n",
    "                else:\n",
    "                    w = (\n",
    "                        self.parameters[\"endo\"][data[\"p1_left\"]]\n",
    "                        * self.parameters[\"endo\"][data[\"p1_right\"]]\n",
    "                    )\n",
    "            nx.set_edge_attributes(\n",
    "                new_graph,\n",
    "                {(source, target): {\"weight\": w}},\n",
    "            )\n",
    "        return new_graph\n",
    "\n",
    "    def compute_dp_dw(self, guess_df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        dP / dw\n",
    "        Change of P based on w\n",
    "        Sx1 vector\n",
    "        \"\"\"\n",
    "        longest_key = sorted(self.keys, key=len)[-1]\n",
    "        prob_traversed = {key: 0 for key in self.keys}\n",
    "        prob_traversed[longest_key] = 1\n",
    "\n",
    "        for sequence, n in prob_traversed.items():\n",
    "            out_edges = [\n",
    "                (source, target, data)\n",
    "                for source, target, data in self.graph.out_edges(sequence, data=True)\n",
    "            ]\n",
    "            weights = np.array([weight[\"weight\"] for _, _, weight in out_edges])\n",
    "            edges_to = [edge_to for _, edge_to, _ in out_edges]\n",
    "            for w, e in zip(weights, edges_to):\n",
    "                prob_traversed[e] += w * n\n",
    "\n",
    "        dp_dw = {}\n",
    "\n",
    "        for key in self.keys:\n",
    "            out_edges = self.graph.out_edges(key)\n",
    "            for (\n",
    "                source,\n",
    "                target,\n",
    "            ) in out_edges:  # P(longest to source) * (P(target) - onehot(source))\n",
    "                dp_dw[(source, target)] = prob_traversed[source] * (\n",
    "                    guess_df[target].values - create_one_hot(self.keys, source)\n",
    "                )\n",
    "\n",
    "        return dp_dw\n",
    "\n",
    "    def update_weights(self, grad, grad_reg=None) -> nx.DiGraph:\n",
    "        diffs = {}\n",
    "        k = 1\n",
    "\n",
    "        old_graph = nx.DiGraph()\n",
    "        for source, target, data in self.graph.edges(data=True):\n",
    "            old_graph.add_edge(source, target, weight=data[\"weight\"])\n",
    "\n",
    "        old_loss = self.losses[-1]\n",
    "\n",
    "        for source in self.graph.nodes():\n",
    "            sum_old_weight = sum(\n",
    "                [\n",
    "                    data[\"weight\"]\n",
    "                    for _, _, data in self.graph.out_edges(source, data=True)\n",
    "                ]\n",
    "            )\n",
    "            sum_diffs = 0\n",
    "\n",
    "            for source, target in self.graph.out_edges(source):\n",
    "                old_weight = self.graph[source][target][\"weight\"]\n",
    "                grad_weight = grad[(source, target)]\n",
    "\n",
    "                if grad_reg:  # if we regularize\n",
    "                    grad_weight += grad_reg[(source, target)]\n",
    "\n",
    "                new_weight = max(0, old_weight - self.lr * grad_weight)\n",
    "                diff = new_weight - old_weight  # diff is -lr*grad\n",
    "                sum_diffs += diff\n",
    "                diffs[(source, target)] = diff\n",
    "\n",
    "            while (sum_old_weight + k * sum_diffs) >= 1:\n",
    "                k = k / 2\n",
    "\n",
    "        new_graph = self.graph.copy()\n",
    "\n",
    "        while True:\n",
    "            # Update graph\n",
    "            for source, target in new_graph.edges():\n",
    "                nx.set_edge_attributes(\n",
    "                    new_graph,\n",
    "                    {\n",
    "                        (source, target): {\n",
    "                            \"weight\": max(\n",
    "                                0,\n",
    "                                old_graph[source][target][\"weight\"]\n",
    "                                + diffs[(source, target)] * k,\n",
    "                            )\n",
    "                        }\n",
    "                    },\n",
    "                )\n",
    "\n",
    "            # Get new KL\n",
    "            new_guess, _ = self.generate_output(new_graph)\n",
    "\n",
    "            new_loss = KL(self.true_dict_vals, list(new_guess.values())) + (\n",
    "                get_l2(new_graph) * self.lam\n",
    "            )\n",
    "\n",
    "            if new_loss <= old_loss:\n",
    "                return new_graph\n",
    "\n",
    "            if k < 1e-15:\n",
    "                return old_graph\n",
    "\n",
    "            k = k / 2\n",
    "            new_graph = self.graph  # resets the new_graph to graph\n",
    "\n",
    "    def update_parameters(self, dL_dtheta):\n",
    "        \"\"\"\n",
    "\n",
    "        Update the parameters with dL_dtheta\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def compute_dL_dp(self, true, guess):\n",
    "        return -np.array(true) / (np.array(guess) + 1e-8)\n",
    "\n",
    "    def compute_dL_dw(self, dL_dp, dp_dw):\n",
    "        \"\"\"\n",
    "        Gradient\n",
    "        \"\"\"\n",
    "        dL_dw = {}\n",
    "        for edge, val in dp_dw.items():\n",
    "            dL_dw[edge] = np.sum(val * dL_dp)\n",
    "        return dL_dw\n",
    "\n",
    "    def get_grad_reg_l2(self, graph):\n",
    "        grad_reg = {}\n",
    "        for source in graph.nodes():\n",
    "            for _, target, data in graph.out_edges(source, data=True):\n",
    "                grad_reg[(source, target)] = 2 * data[\"weight\"] * self.lam  # + self.lam\n",
    "        return grad_reg\n",
    "\n",
    "    def drop_weights(self, threshold: float = 0.01):\n",
    "        \"\"\"\n",
    "        Idea, drop edges that are very small\n",
    "        \"\"\"\n",
    "        new_graph = nx.DiGraph()\n",
    "        for source, target, data in self.graph.edges(data=True):\n",
    "            if data[\"weight\"] > threshold:\n",
    "                new_graph.add_edge(source, target, weight=data[\"weight\"])\n",
    "        return new_graph\n",
    "\n",
    "    def dw_dtheta(self):\n",
    "        \"gradient of theta\"\n",
    "        dw_dtheta = {\n",
    "            \"endo\": 1 - self.parameters[\"stop\"],\n",
    "            \"exo\": 1 - self.parameters[\"stop\"],\n",
    "            \"stop\": 0,\n",
    "        }\n",
    "        return dw_dtheta\n",
    "\n",
    "    def compute_dL_dtheta(self, dL_dw, dw_dtheta):\n",
    "        \"\"\"\n",
    "        dL/dtheta = dL/dw * dw/dtheta\n",
    "        \"\"\"\n",
    "        dL_dtheta = {}\n",
    "        for edge, val in dL_dw.items():\n",
    "            data = self.graph[edge]\n",
    "            dL_dtheta[edge] = val * dw_dtheta[data[\"type\"]]  # 1x1 * 1x1\n",
    "\n",
    "        return dL_dtheta\n",
    "\n",
    "\n",
    "def create_one_hot(keys, key):\n",
    "    one_hot = np.zeros(len(keys))\n",
    "    one_hot[keys.index(key)] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def get_solvable(out_edges, p_generated):\n",
    "    solvable = []\n",
    "    for source, targets in out_edges.items():\n",
    "        if (\n",
    "            set(targets).issubset(set((p_generated.keys())))\n",
    "            and source not in p_generated.keys()\n",
    "        ):\n",
    "            solvable.append(source)\n",
    "    return solvable\n",
    "\n",
    "\n",
    "def get_l1(graph):\n",
    "    return sum([abs(data[\"weight\"]) for _, _, data in graph.edges(data=True)])\n",
    "\n",
    "\n",
    "def get_l2(graph):\n",
    "    return sum([data[\"weight\"] ** 2 for _, _, data in graph.edges(data=True)])\n",
    "\n",
    "\n",
    "def get_elastic_net(graph, lambda_1, lambda_2):\n",
    "    return sum(\n",
    "        [\n",
    "            (lambda_1 * abs(data[\"weight\"]))  # L1\n",
    "            + (lambda_2 * data[\"weight\"] ** 2)  # L2\n",
    "            for _, _, data in graph.edges(data=True)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo estimate of parameters\n",
    "\n",
    "1. Simulate distribution with parameters\n",
    "2. Calc KL.\n",
    "3. Update parameters numerically\n",
    "\n",
    "Repeat until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'endo': {'V': 0.05,\n",
       "  'I': 0.05,\n",
       "  'L': 0.05,\n",
       "  'E': 0.05,\n",
       "  'Q': 0.05,\n",
       "  'D': 0.05,\n",
       "  'N': 0.05,\n",
       "  'H': 0.05,\n",
       "  'W': 0.05,\n",
       "  'F': 0.05,\n",
       "  'Y': 0.05,\n",
       "  'R': 0.05,\n",
       "  'K': 0.05,\n",
       "  'S': 0.05,\n",
       "  'T': 0.05,\n",
       "  'M': 0.05,\n",
       "  'A': 0.05,\n",
       "  'G': 0.05,\n",
       "  'P': 0.05,\n",
       "  'C': 0.05},\n",
       " 'exo': 0.25,\n",
       " 'stop': 0.5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from disassembly.util import amino_acids\n",
    "\n",
    "exo = 0.25\n",
    "parameters = {\n",
    "    \"endo\": {aa: 1 / len(amino_acids.values()) for aa in amino_acids.values()},\n",
    "    \"exo\": exo,\n",
    "    \"stop\": 0.5,\n",
    "}  # endo is dict of aa at p1\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 499 / 500 (3451)\n",
      "88 unique peptides. 501 total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SLLQRVHSGLQLPKGQHVFLAK': 26,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 26,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAK': 24,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 24,\n",
       " 'SLLQRVHSGLQLPKGQHVFLA': 22,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 19,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAK': 17,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKK': 15,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 14,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 14,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 13,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 13,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQA': 12,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 12,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPK': 11,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 11,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKK': 10,\n",
       " 'GLRKSLLQRVHSGLQLPKGQHVFLAK': 9,\n",
       " 'GLRKSLLQRVHSGLQLPKGQHVFLA': 9,\n",
       " 'RVHSGLQLPKGQHVFLAKKPQQARSLLQR': 8,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 7,\n",
       " 'KGQHVFLAKKPQQARSLLQ': 7,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKK': 7,\n",
       " 'KGQHVFLAKKPQQARSLLQR': 6,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAK': 6,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLA': 6,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSL': 6,\n",
       " 'MAHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 5,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 5,\n",
       " 'GQHVFLAKKPQQARSLLQR': 5,\n",
       " 'RVHSGLQLPKGQHVFLAKKPQQARSLLQ': 5,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 5,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQARSL': 5,\n",
       " 'MAHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 4,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 4,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 4,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQ': 4,\n",
       " 'RVHSGLQLPKGQHVFLAK': 4,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKK': 4,\n",
       " 'GQHVFLAKKPQQARSLLQ': 3,\n",
       " 'VHSGLQLPKGQHVFLAKKPQQARSLLQR': 3,\n",
       " 'GLRKSLLQRVHSGLQLPKGQHVFLAKKPQQA': 3,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 3,\n",
       " 'VHSGLQLPKGQHVFLAKKPQQA': 3,\n",
       " 'SLLQRVHSGLQLPK': 3,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFLAK': 3,\n",
       " 'LLQRVHSGLQLPKGQHVFLAK': 3,\n",
       " 'VHSGLQLPKGQHVFLAKKPQQARSLLQ': 3,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLA': 3,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKK': 3,\n",
       " 'MAHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 3,\n",
       " 'KGQHVFLAKKPQQARSLL': 3,\n",
       " 'RVHSGLQLPKGQHVFLAKK': 3,\n",
       " 'VHSGLQLPKGQHVFLAK': 2,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKKPQQA': 2,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKKPQQAR': 2,\n",
       " 'KSLLQRVHSGLQLPK': 2,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 2,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 2,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 2,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQAR': 2,\n",
       " 'RVHSGLQLPKGQHVFLAKKPQQARSLL': 2,\n",
       " 'GLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 2,\n",
       " 'GLRKSLLQRVHSGLQLPKGQHVFL': 2,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAK': 2,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFLAKK': 2,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQAR': 2,\n",
       " 'HVRGLRKSLLQRVHSGLQLPK': 2,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSL': 2,\n",
       " 'MAHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV': 1,\n",
       " 'GQHVFLAKKPQQARSLL': 1,\n",
       " 'KKPQQARSLLQR': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV': 1,\n",
       " 'LRKSLLQRVHSGLQLPKGQHVFLAK': 1,\n",
       " 'SLLQRVHSGLQLPKGQHVFL': 1,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFLAKKPQQAR': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLA': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPK': 1,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKKPQQARSL': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLP': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARS': 1,\n",
       " 'RGLRKSLLQRVHSGLQLPKGQHVFLAK': 1,\n",
       " 'GLRKSLLQRVHSGLQLPK': 1,\n",
       " 'VHSGLQLPKGQHVFLA': 1,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKK': 1,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKKPQQA': 1,\n",
       " 'RVHSGLQLPKGQHVFLAKKPQQARSL': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein = \"MAHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV\"\n",
    "from disassembly.simulate_proteolysis import simulate_proteolysis, enzyme_set, enzyme\n",
    "\n",
    "enzymes = enzyme_set(\n",
    "    [\n",
    "        enzyme({\"K\": 1}, \"protease_iv\"),\n",
    "        enzyme({\"K\": 0.5, \"R\": 0.5}, \"trypsin\"),\n",
    "        enzyme({\"V\": 0.5, \"I\": 0.25, \"A\": 0.15, \"T\": 0.1}, \"elne\"),\n",
    "    ],\n",
    "    [1, 0, 0],  # activities\n",
    "    [1, 0, 0],  # abundances\n",
    ")\n",
    "\n",
    "\n",
    "true_dict, sequence_graph = simulate_proteolysis(\n",
    "    protein,\n",
    "    n_start=1,\n",
    "    n_generate=500,\n",
    "    endo_or_exo_probability=[0.9, 0.1],\n",
    "    enzymes=enzymes,\n",
    ")\n",
    "dict(sorted(true_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 199 / 200 (813)\n",
      "104 unique peptides. 201 total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV': 1,\n",
       " 'MAHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 1,\n",
       " 'MAHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 2,\n",
       " 'LQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 1,\n",
       " 'LQLPKGQHVFLAKKPQQARSLLQ': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV': 3,\n",
       " 'LRKSLLQRVHSGLQLPKGQHVFLAKKPQQA': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 3,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV': 4,\n",
       " 'QLPKGQHVFLAKKPQQARSLLQ': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 7,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 2,\n",
       " 'LQRVHSGLQLPKGQHVFLAKK': 1,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAK': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 14,\n",
       " 'LPKGQHVFLAKKPQQARSLLQR': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQ': 2,\n",
       " 'LRKSLLQRVHSGLQLPKGQHVFLAKKPQQ': 1,\n",
       " 'GQHVFLAKKPQQARSLLQR': 1,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 3,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 5,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAK': 2,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAK': 4,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 10,\n",
       " 'LPKGQHVFLAKKPQQARSLL': 1,\n",
       " 'QRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 2,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 8,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPK': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQA': 3,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSL': 3,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFL': 4,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARS': 1,\n",
       " 'RGLRKSLLQRVHSGLQLPKGQHVFLAKK': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 8,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 2,\n",
       " 'LQRVHSGLQLPKGQHVFLAKKPQQA': 1,\n",
       " 'VHSGLQLPKGQHVFLAKKPQQARSLLQ': 2,\n",
       " 'LRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 1,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 2,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLA': 1,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKKPQQARSL': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQ': 1,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKKP': 2,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFL': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV': 2,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLA': 2,\n",
       " 'RGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV': 3,\n",
       " 'LQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 2,\n",
       " 'HSGLQLPKGQHVFLAKKPQQA': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQAR': 2,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQQARSL': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 4,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARS': 1,\n",
       " 'LLQRVHSGLQLPKGQHVFLAK': 1,\n",
       " 'QRVHSGLQLPKGQHVFLAKK': 1,\n",
       " 'GLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQRV': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKP': 1,\n",
       " 'PKGQHVFLAKKPQQARSLLQR': 1,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKKPQ': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSL': 1,\n",
       " 'LAKKPQQARSLLQ': 1,\n",
       " 'LQRVHSGLQLPKGQHVFLAKKPQQARSLL': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPK': 1,\n",
       " 'LQLPKGQHVFLAKKPQQARSLLQR': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQAR': 2,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVF': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLP': 2,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKKPQ': 1,\n",
       " 'MAHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 1,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFLAKKPQ': 2,\n",
       " 'GLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 2,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQ': 1,\n",
       " 'SGLQLPKGQHVFLAKKP': 1,\n",
       " 'LRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 4,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFL': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVF': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQ': 2,\n",
       " 'RGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQR': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQAR': 2,\n",
       " 'RGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 5,\n",
       " 'RGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 1,\n",
       " 'LRKSLLQRVHSGLQLPKGQHVFLAKKPQQAR': 2,\n",
       " 'KSLLQRVHSGLQLPKGQHVFLAKKPQQARSLLQ': 1,\n",
       " 'QLPKGQHVFLAKKPQQARSLLQR': 1,\n",
       " 'HSGLQLPKGQHVFLAKKPQQARS': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQL': 1,\n",
       " 'RGLRKSLLQRVHSGLQLPKGQHVFLAK': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQ': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQA': 1,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFLAKKPQQAR': 1,\n",
       " 'HVRGLRKSLLQRVHSGLQLPKGQHV': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQH': 1,\n",
       " 'HVFLAKKPQQARSLL': 1,\n",
       " 'RKSLLQRVHSGLQLPKGQHVFLA': 1,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKKPQQARS': 1,\n",
       " 'LLQRVHSGLQLPKGQHVFLAKKPQQA': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHV': 1,\n",
       " 'GLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSLL': 1,\n",
       " 'VRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQARSL': 1,\n",
       " 'LQRVHSGLQLPKGQHVFLAKKPQQARSL': 1,\n",
       " 'AHVRGLRKSLLQRVHSGLQLPKGQHVFLAKKPQQ': 1,\n",
       " 'QRVHSGLQLPKGQHVFLAKKPQQAR': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from disassembly.util import normalize_dict\n",
    "\n",
    "def generate_guess(parameters, protein):\n",
    "    parameters[\"endo\"] = normalize_dict(parameters[\"endo\"])\n",
    "    parameter_enzyme = enzyme_set([enzyme(parameters[\"endo\"], \"\")], [1], [1])\n",
    "    guess, _ = simulate_proteolysis(\n",
    "        protein,\n",
    "        parameter_enzyme,\n",
    "        n_start = 1,\n",
    "        n_generate=200,\n",
    "        endo_or_exo_probability=[1 - parameters[\"exo\"], parameters[\"exo\"]],\n",
    "    )\n",
    "    return guess\n",
    "\n",
    "\n",
    "generated = generate_guess(parameters, protein)\n",
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 199 / 200 (753)\n",
      "103 unique peptides. 201 total\n"
     ]
    }
   ],
   "source": [
    "from disassembly.util import KL, normalize_dict\n",
    "\n",
    "\n",
    "def compare(P, generated):\n",
    "    P = normalize_dict(P)\n",
    "    generated = normalize_dict(generated)\n",
    "    P_vec = []\n",
    "    generated_vec = []\n",
    "    for key in P.keys():\n",
    "        P_vec.append(P[key])\n",
    "        if key in generated.keys():\n",
    "            generated_vec.append(generated[key])\n",
    "        else:\n",
    "            generated_vec.append(0)\n",
    "    for key in generated.keys():\n",
    "        if key not in P.keys():\n",
    "            P_vec.append(0)\n",
    "            generated_vec.append(generated[key])\n",
    "    return P_vec, generated_vec\n",
    "\n",
    "\n",
    "generated = generate_guess(parameters, protein)\n",
    "p, q = compare(true_dict, generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 199 / 200 (870)\n",
      "118 unique peptides. 201 total\n",
      " 199 / 200 (738)\n",
      "111 unique peptides. 201 total\n",
      " 199 / 200 (876)\n",
      "108 unique peptides. 201 total\n",
      " 199 / 200 (718)\n",
      "107 unique peptides. 201 total\n",
      " 199 / 200 (795)\n",
      "113 unique peptides. 201 total\n",
      " 199 / 200 (692)\n",
      "104 unique peptides. 201 total\n",
      " 199 / 200 (1037)\n",
      "111 unique peptides. 201 total\n",
      " 199 / 200 (734)\n",
      "103 unique peptides. 201 total\n",
      " 199 / 200 (794)\n",
      "114 unique peptides. 201 total\n",
      " 199 / 200 (755)\n",
      "102 unique peptides. 201 total\n",
      " 199 / 200 (723)\n",
      "103 unique peptides. 201 total\n",
      " 199 / 200 (875)\n",
      "113 unique peptides. 201 total\n",
      " 199 / 200 (672)\n",
      "106 unique peptides. 201 total\n",
      " 199 / 200 (718)\n",
      "98 unique peptides. 201 total\n",
      " 199 / 200 (733)\n",
      "104 unique peptides. 201 total\n",
      " 199 / 200 (764)\n",
      "115 unique peptides. 201 total\n",
      " 199 / 200 (911)\n",
      "111 unique peptides. 201 total\n",
      " 199 / 200 (843)\n",
      "116 unique peptides. 201 total\n",
      " 199 / 200 (778)\n",
      "109 unique peptides. 201 total\n",
      " 199 / 200 (1027)\n",
      "118 unique peptides. 201 total\n",
      " 199 / 200 (734)\n",
      "106 unique peptides. 201 total\n",
      " 199 / 200 (830)\n",
      "109 unique peptides. 201 total\n",
      " 199 / 200 (623)\n",
      "103 unique peptides. 201 total\n",
      " 199 / 200 (656)\n",
      "100 unique peptides. 201 total\n",
      " 199 / 200 (754)\n",
      "110 unique peptides. 201 total\n",
      " 199 / 200 (803)\n",
      "110 unique peptides. 201 total\n",
      " 199 / 200 (1025)\n",
      "106 unique peptides. 201 total\n",
      " 199 / 200 (711)\n",
      "111 unique peptides. 201 total\n",
      " 199 / 200 (804)\n",
      "102 unique peptides. 201 total\n",
      " 199 / 200 (712)\n",
      "109 unique peptides. 201 total\n",
      " 199 / 200 (859)\n",
      "117 unique peptides. 201 total\n",
      " 199 / 200 (847)\n",
      "114 unique peptides. 201 total\n",
      " 199 / 200 (878)\n",
      "118 unique peptides. 201 total\n",
      " 199 / 200 (859)\n",
      "121 unique peptides. 201 total\n",
      " 199 / 200 (662)\n",
      "103 unique peptides. 201 total\n",
      " 199 / 200 (728)\n",
      "94 unique peptides. 201 total\n",
      " 199 / 200 (739)\n",
      "116 unique peptides. 201 total\n",
      " 199 / 200 (793)\n",
      "115 unique peptides. 201 total\n",
      " 199 / 200 (734)\n",
      "112 unique peptides. 201 total\n",
      " 199 / 200 (711)\n",
      "111 unique peptides. 201 total\n",
      " 199 / 200 (689)\n",
      "98 unique peptides. 201 total\n",
      " 199 / 200 (780)\n",
      "104 unique peptides. 201 total\n",
      " 199 / 200 (707)\n",
      "108 unique peptides. 201 total\n",
      " 199 / 200 (675)\n",
      "110 unique peptides. 201 total\n",
      " 199 / 200 (928)\n",
      "112 unique peptides. 201 total\n",
      " 199 / 200 (718)\n",
      "107 unique peptides. 201 total\n",
      " 199 / 200 (770)\n",
      "106 unique peptides. 201 total\n",
      " 199 / 200 (843)\n",
      "119 unique peptides. 201 total\n",
      " 199 / 200 (760)\n",
      "119 unique peptides. 201 total\n",
      " 199 / 200 (738)\n",
      "116 unique peptides. 201 total\n",
      " 199 / 200 (690)\n",
      "103 unique peptides. 201 total\n",
      " 199 / 200 (745)\n",
      "110 unique peptides. 201 total\n",
      " 199 / 200 (702)\n",
      "104 unique peptides. 201 total\n",
      " 199 / 200 (861)\n",
      "107 unique peptides. 201 total\n",
      " 199 / 200 (689)\n",
      "107 unique peptides. 201 total\n",
      " 199 / 200 (926)\n",
      "113 unique peptides. 201 total\n",
      " 199 / 200 (764)\n",
      "110 unique peptides. 201 total\n",
      " 199 / 200 (876)\n",
      "110 unique peptides. 201 total\n",
      " 199 / 200 (698)\n",
      "103 unique peptides. 201 total\n",
      " 199 / 200 (753)\n",
      "95 unique peptides. 201 total\n",
      " 199 / 200 (704)\n",
      "103 unique peptides. 201 total\n",
      " 199 / 200 (808)\n",
      "112 unique peptides. 201 total\n",
      " 199 / 200 (785)\n",
      "108 unique peptides. 201 total\n",
      " 199 / 200 (874)\n",
      "102 unique peptides. 201 total\n",
      " 199 / 200 (810)\n",
      "116 unique peptides. 201 total\n",
      " 199 / 200 (812)\n",
      "117 unique peptides. 201 total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'endo': {'V': 0.058536342209056125,\n",
       "  'I': 0.05903251045256554,\n",
       "  'L': 0.0489294798464645,\n",
       "  'E': 0.0490295098524655,\n",
       "  'Q': 0.0490295098524655,\n",
       "  'D': 0.049029509852465514,\n",
       "  'N': 0.049029509852465486,\n",
       "  'H': 0.049029509852465514,\n",
       "  'W': 0.04902950985246549,\n",
       "  'F': 0.0490295098524655,\n",
       "  'Y': 0.0490295098524655,\n",
       "  'R': 0.04902950985246551,\n",
       "  'K': 0.049029509852465486,\n",
       "  'S': 0.049029509852465514,\n",
       "  'T': 0.04902950985246549,\n",
       "  'M': 0.04902950985246551,\n",
       "  'A': 0.0490295098524655,\n",
       "  'G': 0.04902950985246551,\n",
       "  'P': 0.04902950985246549,\n",
       "  'C': 0.04902950985246551},\n",
       " 'exo': 0.25,\n",
       " 'stop': 0.5}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update endo\n",
    "\n",
    "# update exo and stop\n",
    "\n",
    "lr = 1e-2\n",
    "\n",
    "losses = []\n",
    "loss_to_beat = KL(p, q)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\r {i}\", end=\"\", flush=True)\n",
    "    for aa in parameters[\"endo\"].keys():\n",
    "        e = lr\n",
    "        parameters[\"endo\"][aa] = parameters[\"endo\"][aa] + e\n",
    "        new_guess = generate_guess(parameters, protein)\n",
    "        p, q = compare(true_dict, new_guess)\n",
    "        new_loss = KL(p, q)\n",
    "        if new_loss > loss_to_beat:\n",
    "            parameters[\"endo\"][aa] -= e\n",
    "        else:\n",
    "            loss_to_beat = new_loss\n",
    "            losses.append(new_loss)\n",
    "\n",
    "    for param in [\"stop\", \"exo\"]:\n",
    "        e = lr\n",
    "        parameters[param] = parameters[param] + e\n",
    "        new_guess = generate_guess(parameters, protein)\n",
    "        p, q = compare(true_dict, new_guess)\n",
    "        new_loss = KL(p, q)\n",
    "        if new_loss > loss_to_beat:\n",
    "            parameters[param] -= e\n",
    "        else:\n",
    "            loss_to_beat = new_loss\n",
    "            losses.append(new_loss)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16c725bb0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
