{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99 / 100 (266)\n",
      "78 unique peptides. 101 total\n"
     ]
    }
   ],
   "source": [
    "protein = \"MAHVRGLQLPGCLALAALCSLVHSQHVFLAPQQARSLLQRVRRANTFLEEVRKGNLERECVEETCSYEEAFEALESSTATDVFWAKYTACETARTPRDKLAACLEGNCAEGLGTNYRGHVNITRSGIECQLWRSRYPHKPEINSTTHPGADLQENFCRNPDSSTTGPWCYTTDPTVRRQECSIPVCGQDQVTVAMTPRSEGSSVNLSPPLEQCVPDRGQQYQGRLAVTTHGLPCLAWASAQAKALSKHQDFNSAVQLVENFCRNPDGDEEGVWCYVAGKPGDFGYCDLNYCEEAVEEETGDGLDEDSDRAIEGRTATSEYQTFFNPRTFGSGEADCGLRPLFEKKSLEDKTERELLESYIDGRIVEGSDAEIGMSPWQVMLFRKSPQELLCGASLISDRWVLTAAHCLLYPPWDKNFTENDLLVRIGKHSRTRYERNIEKISMLEKIYIHPRYNWRENLDRDIALMKLKKPVAFSDYIHPVCLPDRETAASLLQAGYKGRVTGWGNLKETWTANVGKGQPSVLQVVNLPIVERPVCKDSTRIRITDNMFCAGYKPDEGKRGDACEGDSGGPFVMKSPFNNRWYQMGIVSWGEGCDRDGKYGFYTHVFRLKKWIQKVIDQFGE\"\n",
    "from disassembly.simulate_proteolysis import simulate_proteolysis, enzyme_set, enzyme\n",
    "\n",
    "enzymes = enzyme_set(\n",
    "    [\n",
    "        enzyme({\"K\": 1}, \"protease_iv\"),\n",
    "        enzyme({\"K\": 0.5, \"R\": 0.5}, \"trypsin\"),\n",
    "        enzyme({\"V\": 0.5, \"I\": 0.25, \"A\": 0.15, \"T\": 0.1}, \"elne\"),\n",
    "    ],\n",
    "    [1, 1, 0],  # activities\n",
    "    [1, 1, 0],  # abundances\n",
    ")\n",
    "\n",
    "\n",
    "P, sequence_graph = simulate_proteolysis(\n",
    "    protein,\n",
    "    n_start=1,\n",
    "    n_generate=100,\n",
    "    endo_or_exo_probability=[0.9, 0.1],\n",
    "    enzymes=enzymes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate descent\n",
    "\n",
    "\n",
    "\n",
    "```py\n",
    "\n",
    "G = #graph with weights\n",
    "\n",
    "#Sort weights so that we start from the outgoing weights from largest nodes (\"to the left\").\n",
    "\n",
    "for i in range(n_iterations): \n",
    "    for w in weights:   \n",
    "        grad = compute_dL_dw() # compute gradient dependent on w\n",
    "        w = w - grad * lr * k #update weight, make sure that sum(weights from outgoing node) < 1\n",
    "        \n",
    "\n",
    "        \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-paramterization\n",
    "\n",
    "We parameterize\n",
    "\n",
    "$w(\\theta)$ where $\\theta$ is constant for amino-acids and exoprotease\n",
    "\n",
    "theta = {\"A\":a, \"B\": b ..., \"exo\":exo} where \"A\" and \"B\" are p1-amino-acids.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from disassembly.util import KL, amino_acids\n",
    "\n",
    "\n",
    "class WeightEstimatorGD:\n",
    "    \"\"\"\n",
    "    Class to estimate weights using gradient descent.\n",
    "\n",
    "    ```\n",
    "    wegd = WeightEstimatorGD(lr, n_iterations, lam)\n",
    "    generated_graph = wegd(true_dict, verbose=True)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float,\n",
    "        n_iterations: int,\n",
    "        lam: float,\n",
    "    ) -> None:\n",
    "        self.lr = lr\n",
    "        self.n_iterations = n_iterations\n",
    "        self.lam = lam\n",
    "\n",
    "    def run(self, true_dict: dict, verbose: bool):\n",
    "        exo = 0.1\n",
    "        self.parameters = {\n",
    "            \"endo\": {\n",
    "                aa: 1 / (len(amino_acids.values()) + exo) for aa in amino_acids.values()\n",
    "            },\n",
    "            \"exo\": exo,\n",
    "            \"stop\": 0.25,\n",
    "        }  # endo is dict of aa at p1\n",
    "\n",
    "        self.true_dict = true_dict\n",
    "        self.keys = list(true_dict.keys())\n",
    "        self.true_dict_vals = list(true_dict.values())\n",
    "        self.graph = self.create_graph()  # creates the graph from keys\n",
    "\n",
    "        self.generated = {}\n",
    "        self.losses = []\n",
    "        self.weights = {}\n",
    "\n",
    "        for iteration in range(self.n_iterations):\n",
    "            guess, guess_df = self.generate_output(self.graph)\n",
    "            self.generated[iteration] = guess\n",
    "            self.weights[iteration] = np.array(\n",
    "                [data[\"weight\"] for _, _, data in self.graph.edges(data=True)]\n",
    "            )\n",
    "            # Compute loss\n",
    "            kl = KL(self.true_dict_vals, guess.values())\n",
    "            reg = get_l2(self.graph) * self.lam\n",
    "            loss = kl + reg\n",
    "            self.losses.append(loss)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"\\r {iteration} / {self.n_iterations} | {loss:.2f}, kl: {kl:.2f}, reg: {reg:.2f}  | nz: { np.sum( self.weights[iteration] > 0.01 )} | \",\n",
    "                    end=\"\",\n",
    "                    flush=True,\n",
    "                )\n",
    "\n",
    "            # Compute gradient\n",
    "            dp_dw = self.compute_dp_dw(guess_df)\n",
    "            dL_dp = self.compute_dL_dp(self.true_dict_vals, list(guess.values()))\n",
    "            gradient = self.compute_dL_dw(dL_dp, dp_dw)\n",
    "            grad_reg = self.get_grad_reg_l2(self.graph)\n",
    "\n",
    "            # Update graph\n",
    "            self.graph = self.update_weights(gradient, grad_reg)\n",
    "\n",
    "            if loss < 0.01:\n",
    "                break\n",
    "\n",
    "        return self.graph\n",
    "\n",
    "    def generate_output(self, graph: nx.DiGraph) -> (dict, pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generates an output dict from a graph\n",
    "        \"\"\"\n",
    "        longest_key = sorted(self.keys, key=len)[-1]\n",
    "        p_generated = {}\n",
    "        terminal_nodes = [node for node in graph.nodes() if graph.out_degree(node) == 0]\n",
    "\n",
    "        for node in terminal_nodes:  # one hot terminal nodes\n",
    "            oh_node = create_one_hot(self.keys, node)\n",
    "            p_generated[node] = oh_node\n",
    "\n",
    "        out_edges = {\n",
    "            source: [\n",
    "                target for _, target in graph.out_edges(source) if source != target\n",
    "            ]\n",
    "            for source in graph.nodes()\n",
    "        }\n",
    "\n",
    "        while len(p_generated.keys()) < len(self.keys):\n",
    "            solvables = get_solvable(out_edges, p_generated)\n",
    "            for solvable in solvables:\n",
    "                p_generated[solvable] = np.zeros(len(self.keys))\n",
    "\n",
    "                for source, target in graph.out_edges(solvable):\n",
    "                    p_target = p_generated[target]\n",
    "                    w_source_target = graph[source][target][\"weight\"]\n",
    "                    p_generated[source] += w_source_target * p_target\n",
    "\n",
    "                w_source_target = 1 - sum(\n",
    "                    [\n",
    "                        data[\"weight\"]\n",
    "                        for _, _, data in graph.out_edges(source, data=True)\n",
    "                    ]\n",
    "                )\n",
    "                p_target = create_one_hot(self.keys, source)\n",
    "                p_generated[source] += w_source_target * p_target\n",
    "\n",
    "        guess = {\n",
    "            self.keys[i]: p_generated[longest_key][i] for i in range(len(self.keys))\n",
    "        }\n",
    "        return guess, pd.DataFrame(p_generated, index=self.keys)\n",
    "\n",
    "    def create_graph(self):\n",
    "        \"\"\"\n",
    "        Each edge has a weight, a type and a p1_left and p1_right\n",
    "\n",
    "        p1_left exists if there has been a cut on the left of the generated peptide\n",
    "        p1_right ---ll---\n",
    "\n",
    "        type is endo or exo\n",
    "\n",
    "        \"\"\"\n",
    "        graph = nx.DiGraph()\n",
    "        graph.add_nodes_from([(k, {\"layer\": len(k)}) for k in self.keys])\n",
    "        for key1 in self.keys:\n",
    "            for key2 in self.keys:\n",
    "                if (key1 in key2) and (key1 != key2):\n",
    "                    if len(key1) == len(key2) - 1:\n",
    "                        endo_or_exo = \"exo\"\n",
    "                        p1_left = None\n",
    "                        p1_right = None\n",
    "                        w = self.parameters[\"exo\"]\n",
    "                    elif key2.startswith(key1):\n",
    "                        endo_or_exo = \"endo\"\n",
    "                        p1_left = None\n",
    "                        p1_right = key1[-1]\n",
    "                        w = self.parameters[\"endo\"][p1_right]\n",
    "                    elif key2.endswith(key1):\n",
    "                        endo_or_exo = \"endo\"\n",
    "                        p1_left = key2[-len(key1) - 1]\n",
    "                        p1_right = None\n",
    "                        w = self.parameters[\"endo\"][p1_left]\n",
    "                    else:  # middle\n",
    "                        endo_or_exo = \"endo\"\n",
    "                        p1_left = key2[key2.find(key1) - 1]\n",
    "                        p1_right = key1[-1]\n",
    "                        w = (\n",
    "                            self.parameters[\"endo\"][p1_left]\n",
    "                            * self.parameters[\"endo\"][p1_right]\n",
    "                        )\n",
    "\n",
    "                    graph.add_edge(\n",
    "                        key2,\n",
    "                        key1,\n",
    "                        weight=w,\n",
    "                        type=endo_or_exo,\n",
    "                        p1_left=p1_left,\n",
    "                        p1_right=p1_right,\n",
    "                    )\n",
    "\n",
    "        return graph\n",
    "\n",
    "    def update_weights_w_parameters(self):\n",
    "        \"\"\"\n",
    "\n",
    "        Updates the graph weights based on self.parameters\n",
    "\n",
    "        \"\"\"\n",
    "        new_graph = self.graph.copy()\n",
    "\n",
    "        for source, target, data in new_graph.edges(data=True):\n",
    "            if data[\"type\"] == \"exo\":\n",
    "                w = self.parameters[\"exo\"]\n",
    "            elif data[\"type\"] == \"endo\":\n",
    "                if data[\"p1_left\"] is None:\n",
    "                    w = self.parameters[\"endo\"][data[\"p1_right\"]]\n",
    "                elif data[\"p1_right\"] is None:\n",
    "                    w = self.parameters[\"endo\"][data[\"p1_left\"]]\n",
    "                else:\n",
    "                    w = (\n",
    "                        self.parameters[\"endo\"][data[\"p1_left\"]]\n",
    "                        * self.parameters[\"endo\"][data[\"p1_right\"]]\n",
    "                    )\n",
    "            nx.set_edge_attributes(\n",
    "                new_graph,\n",
    "                {(source, target): {\"weight\": w}},\n",
    "            )\n",
    "        return new_graph\n",
    "\n",
    "    def compute_dp_dw(self, guess_df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        dP / dw\n",
    "        Change of P based on w\n",
    "        Sx1 vector\n",
    "        \"\"\"\n",
    "        longest_key = sorted(self.keys, key=len)[-1]\n",
    "        prob_traversed = {key: 0 for key in self.keys}\n",
    "        prob_traversed[longest_key] = 1\n",
    "\n",
    "        for sequence, n in prob_traversed.items():\n",
    "            out_edges = [\n",
    "                (source, target, data)\n",
    "                for source, target, data in self.graph.out_edges(sequence, data=True)\n",
    "            ]\n",
    "            weights = np.array([weight[\"weight\"] for _, _, weight in out_edges])\n",
    "            edges_to = [edge_to for _, edge_to, _ in out_edges]\n",
    "            for w, e in zip(weights, edges_to):\n",
    "                prob_traversed[e] += w * n\n",
    "\n",
    "        dp_dw = {}\n",
    "\n",
    "        for key in self.keys:\n",
    "            out_edges = self.graph.out_edges(key)\n",
    "            for (\n",
    "                source,\n",
    "                target,\n",
    "            ) in out_edges:  # P(longest to source) * (P(target) - onehot(source))\n",
    "                dp_dw[(source, target)] = prob_traversed[source] * (\n",
    "                    guess_df[target].values - create_one_hot(self.keys, source)\n",
    "                )\n",
    "\n",
    "        return dp_dw\n",
    "\n",
    "    def update_weights(self, grad, grad_reg=None) -> nx.DiGraph:\n",
    "        diffs = {}\n",
    "        k = 1\n",
    "\n",
    "        old_graph = nx.DiGraph()\n",
    "        for source, target, data in self.graph.edges(data=True):\n",
    "            old_graph.add_edge(source, target, weight=data[\"weight\"])\n",
    "\n",
    "        old_loss = self.losses[-1]\n",
    "\n",
    "        for source in self.graph.nodes():\n",
    "            sum_old_weight = sum(\n",
    "                [\n",
    "                    data[\"weight\"]\n",
    "                    for _, _, data in self.graph.out_edges(source, data=True)\n",
    "                ]\n",
    "            )\n",
    "            sum_diffs = 0\n",
    "\n",
    "            for source, target in self.graph.out_edges(source):\n",
    "                old_weight = self.graph[source][target][\"weight\"]\n",
    "                grad_weight = grad[(source, target)]\n",
    "\n",
    "                if grad_reg:  # if we regularize\n",
    "                    grad_weight += grad_reg[(source, target)]\n",
    "\n",
    "                new_weight = max(0, old_weight - self.lr * grad_weight)\n",
    "                diff = new_weight - old_weight  # diff is -lr*grad\n",
    "                sum_diffs += diff\n",
    "                diffs[(source, target)] = diff\n",
    "\n",
    "            while (sum_old_weight + k * sum_diffs) >= 1:\n",
    "                k = k / 2\n",
    "\n",
    "        new_graph = self.graph.copy()\n",
    "\n",
    "        while True:\n",
    "            # Update graph\n",
    "            for source, target in new_graph.edges():\n",
    "                nx.set_edge_attributes(\n",
    "                    new_graph,\n",
    "                    {\n",
    "                        (source, target): {\n",
    "                            \"weight\": max(\n",
    "                                0,\n",
    "                                old_graph[source][target][\"weight\"]\n",
    "                                + diffs[(source, target)] * k,\n",
    "                            )\n",
    "                        }\n",
    "                    },\n",
    "                )\n",
    "\n",
    "            # Get new KL\n",
    "            new_guess, _ = self.generate_output(new_graph)\n",
    "\n",
    "            new_loss = KL(self.true_dict_vals, list(new_guess.values())) + (\n",
    "                get_l2(new_graph) * self.lam\n",
    "            )\n",
    "\n",
    "            if new_loss <= old_loss:\n",
    "                return new_graph\n",
    "\n",
    "            if k < 1e-15:\n",
    "                return old_graph\n",
    "\n",
    "            k = k / 2\n",
    "            new_graph = self.graph  # resets the new_graph to graph\n",
    "\n",
    "    def update_parameters(self, dL_dtheta):\n",
    "        \"\"\"\n",
    "\n",
    "        Update the parameters with dL_dtheta\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    def compute_dL_dp(self, true, guess):\n",
    "        return -np.array(true) / (np.array(guess) + 1e-8)\n",
    "\n",
    "    def compute_dL_dw(self, dL_dp, dp_dw):\n",
    "        \"\"\"\n",
    "        Gradient\n",
    "        \"\"\"\n",
    "        dL_dw = {}\n",
    "        for edge, val in dp_dw.items():\n",
    "            dL_dw[edge] = np.sum(val * dL_dp)\n",
    "        return dL_dw\n",
    "\n",
    "    def get_grad_reg_l2(self, graph):\n",
    "        grad_reg = {}\n",
    "        for source in graph.nodes():\n",
    "            for _, target, data in graph.out_edges(source, data=True):\n",
    "                grad_reg[(source, target)] = 2 * data[\"weight\"] * self.lam  # + self.lam\n",
    "        return grad_reg\n",
    "\n",
    "    def drop_weights(self, threshold: float = 0.01):\n",
    "        \"\"\"\n",
    "        Idea, drop edges that are very small\n",
    "        \"\"\"\n",
    "        new_graph = nx.DiGraph()\n",
    "        for source, target, data in self.graph.edges(data=True):\n",
    "            if data[\"weight\"] > threshold:\n",
    "                new_graph.add_edge(source, target, weight=data[\"weight\"])\n",
    "        return new_graph\n",
    "\n",
    "    def dw_dtheta(self):\n",
    "        \"gradient of theta\"\n",
    "        dw_dtheta = {\n",
    "            \"endo\": 1 - self.parameters[\"stop\"],\n",
    "            \"exo\": 1 - self.parameters[\"stop\"],\n",
    "            \"stop\": 0,\n",
    "        }\n",
    "        return dw_dtheta\n",
    "\n",
    "    def compute_dL_dtheta(self, dL_dw, dw_dtheta):\n",
    "        \"\"\"\n",
    "        dL/dtheta = dL/dw * dw/dtheta\n",
    "        \"\"\"\n",
    "        dL_dtheta = {}\n",
    "        for edge, val in dL_dw.items():\n",
    "            data = self.graph[edge]\n",
    "            dL_dtheta[edge] = val * dw_dtheta[data[\"type\"]]  # 1x1 * 1x1\n",
    "\n",
    "        return dL_dtheta\n",
    "\n",
    "\n",
    "def create_one_hot(keys, key):\n",
    "    one_hot = np.zeros(len(keys))\n",
    "    one_hot[keys.index(key)] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def get_solvable(out_edges, p_generated):\n",
    "    solvable = []\n",
    "    for source, targets in out_edges.items():\n",
    "        if (\n",
    "            set(targets).issubset(set((p_generated.keys())))\n",
    "            and source not in p_generated.keys()\n",
    "        ):\n",
    "            solvable.append(source)\n",
    "    return solvable\n",
    "\n",
    "\n",
    "def get_l1(graph):\n",
    "    return sum([abs(data[\"weight\"]) for _, _, data in graph.edges(data=True)])\n",
    "\n",
    "\n",
    "def get_l2(graph):\n",
    "    return sum([data[\"weight\"] ** 2 for _, _, data in graph.edges(data=True)])\n",
    "\n",
    "\n",
    "def get_elastic_net(graph, lambda_1, lambda_2):\n",
    "    return sum(\n",
    "        [\n",
    "            (lambda_1 * abs(data[\"weight\"]))  # L1\n",
    "            + (lambda_2 * data[\"weight\"] ** 2)  # L2\n",
    "            for _, _, data in graph.edges(data=True)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo estimate of parameters\n",
    "\n",
    "1. Simulate distribution with parameters\n",
    "2. Calc KL.\n",
    "3. Update parameters numerically\n",
    "\n",
    "Repeat until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'endo': {'V': 0.05,\n",
       "  'I': 0.05,\n",
       "  'L': 0.05,\n",
       "  'E': 0.05,\n",
       "  'Q': 0.05,\n",
       "  'D': 0.05,\n",
       "  'N': 0.05,\n",
       "  'H': 0.05,\n",
       "  'W': 0.05,\n",
       "  'F': 0.05,\n",
       "  'Y': 0.05,\n",
       "  'R': 0.05,\n",
       "  'K': 0.05,\n",
       "  'S': 0.05,\n",
       "  'T': 0.05,\n",
       "  'M': 0.05,\n",
       "  'A': 0.05,\n",
       "  'G': 0.05,\n",
       "  'P': 0.05,\n",
       "  'C': 0.05},\n",
       " 'exo': 0.25,\n",
       " 'stop': 0.5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from disassembly.util import amino_acids\n",
    "\n",
    "exo = 0.25\n",
    "parameters = {\n",
    "    \"endo\": {aa: 1 / (len(amino_acids.values())) for aa in amino_acids.values()},\n",
    "    \"exo\": exo,\n",
    "    \"stop\": 0.5,\n",
    "}  # endo is dict of aa at p1\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99 / 100 (6269)\n",
      "4 unique peptides. 101 total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AHVRGLRSLLQRVHSGLQLPK': 80,\n",
       " 'AHVRGLRSLLQRVHSGLQLPKGQHVFLAK': 19,\n",
       " 'MAHVRGLRSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'AHVRGLRSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein = \"MAHVRGLRSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV\"\n",
    "from disassembly.simulate_proteolysis import simulate_proteolysis, enzyme_set, enzyme\n",
    "\n",
    "enzymes = enzyme_set(\n",
    "    [\n",
    "        enzyme({\"K\": 1}, \"protease_iv\"),\n",
    "        enzyme({\"K\": 0.5, \"R\": 0.5}, \"trypsin\"),\n",
    "        enzyme({\"V\": 0.5, \"I\": 0.25, \"A\": 0.15, \"T\": 0.1}, \"elne\"),\n",
    "    ],\n",
    "    [1, 0, 0],  # activities\n",
    "    [1, 0, 0],  # abundances\n",
    ")\n",
    "\n",
    "\n",
    "P, sequence_graph = simulate_proteolysis(\n",
    "    protein,\n",
    "    n_start=1,\n",
    "    n_generate=100,\n",
    "    endo_or_exo_probability=[.9999,.0001],\n",
    "    enzymes=enzymes,\n",
    ")\n",
    "dict(sorted(P.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 9,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQR': 8,\n",
       " 'VHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 2,\n",
       " 'CLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQR': 2,\n",
       " 'AHVRGLQLPKGCLALAA': 2,\n",
       " 'SLLQRV': 2,\n",
       " 'GLQLPKGQHVFLAKPQQARSLLQRV': 2,\n",
       " 'QRV': 2,\n",
       " 'KPQQARSLLQRV': 2,\n",
       " 'HVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 2,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSL': 2,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVH': 2,\n",
       " 'FLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQR': 1,\n",
       " 'CLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'AKPQQARSLLQRV': 1,\n",
       " 'SQHVFLAKP': 1,\n",
       " 'VRGLQLPKGCLALAALCSLVHSQHVFLAKPQQA': 1,\n",
       " 'LLQRVHSGLQL': 1,\n",
       " 'HVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGL': 1,\n",
       " 'AKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'MAHVRGLQLPKGCLALAA': 1,\n",
       " 'VFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'HVRGLQLPKGCLALAA': 1,\n",
       " 'ALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAK': 1,\n",
       " 'ARS': 1,\n",
       " 'MAHVRGLQLPKG': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSL': 1,\n",
       " 'LAKPQQARSLLQRV': 1,\n",
       " 'KPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQR': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVF': 1,\n",
       " 'LQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLL': 1,\n",
       " 'RSLLQRV': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRV': 1,\n",
       " 'MAHVRGLQLPKGCLALAALC': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVH': 1,\n",
       " 'LLQRV': 1,\n",
       " 'MAHVRGLQLPK': 1,\n",
       " 'Q': 1,\n",
       " 'QQARSLLQRV': 1,\n",
       " 'AHVRGLQLPKGCLALAALCSLVHS': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGL': 1,\n",
       " 'HVFLAKPQQARSLLQRV': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKP': 1,\n",
       " 'LPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQR': 1,\n",
       " 'HSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'ARSLLQR': 1,\n",
       " 'VHSGLQLPKGQHVFLAKPQQARSLLQR': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQA': 1,\n",
       " 'V': 1,\n",
       " 'LCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQR': 1,\n",
       " 'QLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'AHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLP': 1,\n",
       " 'AKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQR': 1,\n",
       " 'SLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFL': 1,\n",
       " 'HSGLQLPKGQHVFLAKPQQARSLLQ': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQ': 1,\n",
       " 'QLPKGQHVFLAKPQQARSLLQR': 1,\n",
       " 'FLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'SLLQ': 1,\n",
       " 'GLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'VRGLQLPKGCLALAALCSLVHSQHVFLAKPQ': 1,\n",
       " 'VFLAKPQQARSLLQRV': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQ': 1,\n",
       " 'RVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'SLLQR': 1,\n",
       " 'CSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'RSLLQRVHSGLQLPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'AHVRGLQ': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQHVFLAKPQQARSLLQRVHSGLQLPKGQHVFLAKPQQA': 1,\n",
       " 'AHVRGLQLP': 1,\n",
       " 'KPQQAR': 1,\n",
       " 'MAHVRGLQLPKGCLALAALCSLVHSQ': 1,\n",
       " 'LPKGQHVFLAKPQQARSLLQRV': 1,\n",
       " 'MAHVRGLQLPKGCLALAAL': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate P with MC and parameters\n",
    "\n",
    "\n",
    "def find_aminoacids_in_sequence(protein_sequence, target_aminoacid):\n",
    "    indexes = [i for i, aa in enumerate(protein_sequence) if aa == target_aminoacid]\n",
    "    if len(protein_sequence) - 1 in indexes:\n",
    "        indexes.remove(len(protein_sequence) - 1)\n",
    "    return indexes\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def generate_guess(parameters, protein):\n",
    "        \n",
    "    n_exo = 0\n",
    "    n_endo = 0\n",
    "    n_particles = 100\n",
    "    generated = {}\n",
    "    for _ in range(n_particles):\n",
    "        sequence = protein\n",
    "        while True:\n",
    "            exo_endo_or_stop = np.random.choice(\n",
    "                [\"exo\", \"endo\", \"stop\"],\n",
    "                p=[\n",
    "                    parameters[\"exo\"],\n",
    "                    (1 - (parameters[\"exo\"] + parameters[\"stop\"])),\n",
    "                    parameters[\"stop\"],\n",
    "                ],\n",
    "            )\n",
    "            if (exo_endo_or_stop == \"stop\" or len(sequence) < 5) and sequence != protein:\n",
    "                if sequence in generated:\n",
    "                    generated[sequence] += 1\n",
    "                else:\n",
    "                    generated[sequence] = 1\n",
    "                break\n",
    "            elif exo_endo_or_stop == \"exo\":\n",
    "                n_exo += 1\n",
    "                u = np.random.uniform(0, 1)\n",
    "                if u < 0.5:\n",
    "                    sequence = sequence[1:]\n",
    "                else:\n",
    "                    sequence = sequence[:-1]\n",
    "            else: \n",
    "                try: # endo\n",
    "                    n_endo += 1\n",
    "\n",
    "                    index_to_cut = {}\n",
    "                    for aminoacid in parameters[\"endo\"].keys():\n",
    "                        indices_for_aminoacid = find_aminoacids_in_sequence(sequence, aminoacid)\n",
    "                        for index in indices_for_aminoacid:\n",
    "                            if index != len(sequence):\n",
    "                                index_to_cut[index] = parameters[\"endo\"][aminoacid]\n",
    "                    cutting_index = int(\n",
    "                        np.random.choice(\n",
    "                            list(index_to_cut.keys()),\n",
    "                            p=[p / sum(index_to_cut.values()) for p in index_to_cut.values()],\n",
    "                        )\n",
    "                    )\n",
    "                    u = np.random.uniform(0, 1)\n",
    "                    if u < 0.5 and len(sequence[:cutting_index]) > 5:\n",
    "    \n",
    "                        sequence = sequence[:cutting_index+1]\n",
    "                    else:\n",
    "                        sequence = sequence[cutting_index+1:]\n",
    "                except:\n",
    "                    continue\n",
    "    return dict(sorted(generated.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "generated = generate_guess(parameters, protein)\n",
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.23842660355932"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from disassembly.util import KL, normalize_dict\n",
    "\n",
    "def compare(P, generated):\n",
    "    P = normalize_dict(P)\n",
    "    generated = normalize_dict(generated)\n",
    "    P_vec = []\n",
    "    generated_vec = []\n",
    "    for key in P.keys():\n",
    "        P_vec.append(P[key])\n",
    "        if key in generated.keys():\n",
    "            generated_vec.append(generated[key])\n",
    "        else:\n",
    "            generated_vec.append(0)\n",
    "    for key in generated.keys():\n",
    "        if key not in P.keys():\n",
    "            P_vec.append(0)\n",
    "            generated_vec.append(generated[key])\n",
    "    return P_vec, generated_vec\n",
    "\n",
    "\n",
    "generated = generate_guess(parameters, protein)\n",
    "p, q = compare(P, generated)\n",
    "KL(p,q)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0endo V 16.23842671163291\n",
      "endo V 16.238425527867484\n",
      "endo V 16.23842552316745\n",
      "endo L 15.14412880228282\n",
      "endo H 11.587660083519324\n",
      " 2endo V 11.587659800641305\n",
      " 3endo N 11.450873492798436\n",
      " 9"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'endo': {'V': 0.019999999999999997,\n",
       "  'I': 0.05,\n",
       "  'L': 0.060000000000000005,\n",
       "  'E': 0.03,\n",
       "  'Q': 0.05,\n",
       "  'D': 0.04,\n",
       "  'N': 0.060000000000000005,\n",
       "  'H': 0.04,\n",
       "  'W': 0.05,\n",
       "  'F': 0.05,\n",
       "  'Y': 0.05,\n",
       "  'R': 0.04,\n",
       "  'K': 0.05,\n",
       "  'S': 0.05,\n",
       "  'T': 0.05,\n",
       "  'M': 0.05,\n",
       "  'A': 0.05,\n",
       "  'G': 0.05,\n",
       "  'P': 0.05,\n",
       "  'C': 0.060000000000000005},\n",
       " 'exo': 0.25,\n",
       " 'stop': 0.5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update parameters\n",
    "\n",
    "import copy\n",
    "\n",
    "# update endo\n",
    "\n",
    "# update exo and stop\n",
    "\n",
    "lr = 1e-2\n",
    "\n",
    "losses = []\n",
    "loss_to_beat = KL(p,q)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"\\r {i}\", end=\"\", flush=True)\n",
    "    for aa in parameters[\"endo\"].keys():\n",
    "        for i in range(10):\n",
    "            e = np.random.choice([lr, -lr])\n",
    "            parameters[\"endo\"][aa] += e\n",
    "            new_guess = generate_guess(parameters, protein)\n",
    "            p,q = compare(P, new_guess)\n",
    "            new_loss = KL(p,q)\n",
    "            if new_loss > loss_to_beat:\n",
    "                parameters[\"endo\"][aa] -= e\n",
    "            else:\n",
    "                print(f\"endo {aa} {new_loss}\")\n",
    "                loss_to_beat = new_loss\n",
    "                losses.append(new_loss)\n",
    "\n",
    "    \n",
    "    for param in [\"stop\",\"exo\"]:\n",
    "        e = np.random.choice([lr, -lr])\n",
    "        parameters[param] += e\n",
    "        new_guess = generate_guess(parameters, protein)\n",
    "        p,q = compare(P, new_guess)\n",
    "        new_loss = KL(p,q)\n",
    "        if new_loss > loss_to_beat:\n",
    "            parameters[param] -= e\n",
    "        else:\n",
    "            loss_to_beat = new_loss\n",
    "            losses.append(new_loss)\n",
    "            print(f\"{param} {new_loss}\")\n",
    "        \n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x169ed6df0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuRklEQVR4nO3de3BU52H38d/ZXe0uuiMJ3YwwYIy4SsgO+BK/NhgMyCDZ7sVJpkOdS6dNxmntuuMENxM7mfR9sTtt3UzMJM40sadtpm7a1BSwMcbYAt9wDFiIm8FgLgLdBeiKVtLuef8QKyPQbWF3z57d72dmx4N0VvweH+/o5/M8zzmGaZqmAAAAosRhdQAAAJBYKB8AACCqKB8AACCqKB8AACCqKB8AACCqKB8AACCqKB8AACCqKB8AACCqXFYHuFIgEFBdXZ3S0tJkGIbVcQAAwDiYpqmOjg4VFhbK4Rj92kbMlY+6ujoVFRVZHQMAAFyD2tpaTZ48edRjYq58pKWlSRoIn56ebnEaAAAwHu3t7SoqKhr8PT6amCsfwamW9PR0ygcAADYzniUTLDgFAABRRfkAAABRRfkAAABRRfkAAABRRfkAAABRRfkAAABRRfkAAABRRfkAAABRRfkAAABRRfkAAABRRfkAAABRRfkAAABRFXMPlouUfn9A//f1w1bHQBikeZM0KdWt7FSPclI9yk51KyfFo/QJrnE90AgAYK2EKR8BU3rp/ZNWx0AEJTkNZad4lJPmHvhnqkc5qe7BgpJ92Z+zUtxKcnLhDwCskDDlw2FIjy65yeoYuE6mKbVd7FNrZ69aOn1q7epVS4dPHb5+9flNNbT3qKG9Z1w/KzM5aaCYpLiVk+ZRTsoVV1MuKyvJbidXVQAgTBKmfLicDj25YpbVMRAhPX1+neu6VEg6e9V86Z8Df/ap5bKycq6rV/6AqQvdfbrQ3adj4/j53iTHpVIyUFIuLyjZqW5NCn4v1a3MZLecDooKAIwkYcoH4ps3yanCzAkqzJww5rGBgKkLF/vU0um79Oq9VFCChSVYVHxq6ejVxT6/evoCOnP+os6cvzjmz3cYUtaVBeXSdFDOZdNCwe95k5zh+FcAALZB+UDCcTgMZaW4lZXi1sy8tDGP7+7tV0tHr1q6fGrpGLh6cvnVlJbLrrKc7+5TwNSl7/WOK0+qx6Wcy9akBKd+clKDa1cGvjYplUW1AOID5QMYQ7LbpSnZLk3JTh7z2H5/4NL0T+/AlZNhp4G++GevP6BOX786ff062do95s8PLqq9fMpnSFFJG1jDMimNRbUAYhflAwgjl9Oh3HSvctO9Yx5rmqY6fP2DV1NaOnxqufTP4JRPa9cX5aWjJ/RFtRkTkoZcORmttKSwqBZAlFA+AIsYhqF0b5LSvUmaPmns4339frV29g5eObl8vUprV+/gn1s6fYOLatsu9qntYp+ON3eN+fM9LsdV25NzLltIe/nXJrKoFsB1oHwANuFxhb6otrXTNzjlE1yn0trlU3PH0Gmh7l6/fP0Bnb1wUWcvjH9RbfYwC2hzhiktLKoFcDnKBxCHLl9Ue/M4F9V+cUXli90/LVeuU+nq1fnu3iGLao80jp0n1eMauNFbiluFmRP0vRWzxrWGBkB8onwAULLbpeQsl4qyxrmotrv3qgW0LZfdV2VwDcsVi2pPtXZr7+kL8ric+seHS6MwMgCxiPIBICQup0O5aV7lpo1/UW2woNScadNPNh/Smwcb1NM3j+kYIEGxDw9AxAQX1U7LSdHCqVn6xp1TlZ/uVYevXzuONlsdD4BFKB8AosbhMLS6pECStHFfncVpAFgl5PKxc+dOVVRUqLCwUIZhaMOGDVcdc/jwYVVWViojI0MpKSlauHChTp8+HY68AGyuckGhJGn74UZ1+fotTgPACiGXj66uLpWWlmr9+vXDfv/48eO66667NGvWLFVVVammpkY//OEP5fWOPT8MIP7NvyFDN2Ynq6cvoLcOj2OrDIC4E/KC0/LycpWXl4/4/R/84Ae6//779fd///eDX7vpJh5lD2CAYRiqLC3Uz94+pk376vTAghusjgQgysK65iMQCOi1117TzJkztWLFCuXm5uq2224bdmomyOfzqb29fcgLQHyrKB2YetlxtFkXusf3AD4A8SOs5aOpqUmdnZ169tlntXLlSr355pt66KGH9Ad/8AfasWPHsO9Zt26dMjIyBl9FRUXhjAQgBs3MS9Os/DT1+U1tPdhgdRwAURb2Kx+S9MADD+iv//qvtWDBAq1du1arV6/WL37xi2Hf89RTT6mtrW3wVVtbG85IAGJU8OoHu16AxBPW8pGTkyOXy6U5c+YM+frs2bNH3O3i8XiUnp4+5AUg/lWUDJSPD4+3qqljfE/pBRAfwlo+3G63Fi5cqCNHjgz5+tGjR3XjjTeG868CYHNTspNVWpSpgCm9XlNvdRwAURTybpfOzk4dO3Zs8M8nTpxQdXW1srKyNGXKFD355JP6yle+orvvvltLlizRG2+8oU2bNqmqqiqcuQHEgcrSQu2rvaBNNfX6+penWR0HQJQYpmmaobyhqqpKS5YsuerrjzzyiF5++WVJ0q9//WutW7dOZ86cUXFxsX784x/rgQceGNfPb29vV0ZGhtra2piCAeJcY3uPbl+3XaYpvff9JZo8kSfdAnYVyu/vkMtHpFE+gMTy1V9+qF2fn9Pa8ln69j3cEwiwq1B+f/NsFwCWGtz1Us2uFyBRUD4AWKp8XoFcDkOH6tt1rKnT6jgAooDyAcBSWSlu3XVzjiRpE/f8ABIC5QOA5SovTb1sqqlTjC1DAxABlA8AlrtvTp48Loc+b+7SwTqe7wTEO8oHAMuleZN076xcSQNXPwDEN8oHgJgQ3PWyeV+9AgGmXoB4RvkAEBPunZWrFLdTZy9c1Ce1562OAyCCKB8AYoI3yanlc/Mlcc8PIN5RPgDEjOCul9f216vfH7A4DYBIoXwAiBlfnpGjzOQktXT26qMT56yOAyBCKB8AYobb5VD5vAJJTL0A8YzyASCmVJQOlI8tB+rV28/UCxCPKB8AYspt07KVm+ZRe0+/dh5ttjoOgAigfACIKU6HoVUlA1c/uOEYEJ8oHwBiTnDXy7ZDjbrY67c4DYBwo3wAiDkLijJVlDVB3b1+bf+00eo4AMKM8gEg5hiGoYqSgasf7HoB4g/lA0BMCj7rpepIs9p7+ixOAyCcKB8AYtKs/DTdnJuqXn9AWw80WB0HQBhRPgDEJMMwBq9+bKqptzgNgHCifACIWcHy8f6xFrV2+ixOAyBcKB8AYta0nBTNvyFD/oCp15l6AeIG5QNATAve82MTu16AuEH5ABDTgnc7/f3Jc6pvu2hxGgDhQPkAENMKMydo0dQsSdLmfSw8BeIB5QNAzAs+6ZZnvQDxgfIBIOaVzy+Q02Go5kybTrR0WR0HwHWifACIeTmpHt15U7YkafM+rn4Adkf5AGALwV0vG/fVyTRNi9MAuB6UDwC2sHxuvtxOhz5r6tSRxg6r4wC4DpQPALaQMSFJi4snSeJJt4DdUT4A2MYXz3ph6gWwM8oHANtYOjtXyW6nas9dVHXtBavjALhGlA8AtpHsdmnZ7DxJ0iZuOAbYFuUDgK0Ed71srqmTP8DUC2BHlA8AtvJ/ZuYo3etSU4dPvz9xzuo4AK4B5QOArXhcTpXPG7jd+kZuOAbYEuUDgO0Ed71sOVCvPn/A4jQAQkX5AGA7t0/PUk6qWxe6+/TeZy1WxwEQIsoHANtxOR1aNf/Sk26ZegFsh/IBwJaCUy9bDzaop89vcRoAoaB8ALClW6ZM1A2ZE9TV69c7nzZZHQdACCgfAGzJ4TC0uoRdL4AdUT4A2FZw6uXtT5vU0dNncRoA40X5AGBbcwvTNT0nRb7+gLYdarQ6DoBxonwAsC3DML540i1TL4BtUD4A2FqwfLz7WYvOd/VanAbAeFA+ANjajNxUzSlIV3/A1JYDDVbHATAOlA8Athe8+rFx31mLkwAYD8oHANsLbrn96MQ5Nbb3WJwGwFgoHwBsrygrWbdMyZRpSptr6q2OA2AMlA8AcaGSXS+AbVA+AMSF+0sK5DCk6toLOt3abXUcAKOgfACIC7lpXt1xU7YkaVMNVz+AWEb5ABA3KkqYegHsgPIBIG6snJevJKehTxs6dLSxw+o4AEZA+QAQNzKT3br75kmSpM1c/QBiFuUDQFypXBC84VidTNO0OA2A4VA+AMSVZbPz5E1y6GRrtw6cbbc6DoBhUD4AxJUUj0tLZ+dJ4nbrQKwKuXzs3LlTFRUVKiwslGEY2rBhw5Dvf/3rX5dhGENeK1euDFdeABhTcNfL5pp6BQJMvQCxJuTy0dXVpdLSUq1fv37EY1auXKn6+vrB13/8x39cV0gACMXi4klK87hU39aj3afOWx0HwBVcob6hvLxc5eXlox7j8XiUn59/zaEA4Hp4k5xaPjdfv9t7Rpv21WnRtCyrIwG4TETWfFRVVSk3N1fFxcX6zne+o9bW1hGP9fl8am9vH/ICgOsV3PXy+v569fsDFqcBcLmwl4+VK1fqX//1X7V9+3Y999xz2rFjh8rLy+X3+4c9ft26dcrIyBh8FRUVhTsSgAR0503Zykpxq7WrVx8cH/l/gABEX9jLx1e/+lVVVlZq/vz5evDBB7V582Z9/PHHqqqqGvb4p556Sm1tbYOv2tracEcCkICSnA7dP39g+ncjNxwDYkrEt9pOnz5dOTk5Onbs2LDf93g8Sk9PH/ICgHAI7nrZeqBBvv7hr74CiL6Il48zZ86otbVVBQUFkf6rAGCIhVOzlJ/uVYevX1VHmq2OA+CSkMtHZ2enqqurVV1dLUk6ceKEqqurdfr0aXV2durJJ5/Url27dPLkSW3fvl0PPPCAZsyYoRUrVoQ7OwCMyuEwtLpk4H98eNItEDtCLh+7d+9WWVmZysrKJElPPPGEysrK9PTTT8vpdKqmpkaVlZWaOXOmvvWtb+nWW2/Vu+++K4/HE/bwADCW4K6Xtw43qsvXb3EaANI13Odj8eLFoz6saevWrdcVCADCaf4NGboxO1mnWrv11uFGPbDgBqsjAQmPZ7sAiGuGYaiydODqB1MvQGygfACIexWXyseOo81q6+6zOA0AygeAuDczL02z8tPU5zf1xsF6q+MACY/yASAhVAxOvVA+AKtRPgAkhOANxz443qKmjh6L0wCJjfIBICFMyU5WaVGmAqa0ZX+D1XGAhEb5AJAwgrteeNYLYC3KB4CEsbqkQIYh7Tl1XmfOd1sdB0hYlA8ACSMv3avbpmVJkjbXsPAUsArlA0BCqeCGY4DlKB8AEkr5vAK5HIYO1rXreHOn1XGAhET5AJBQslLcuuvmHElc/QCsQvkAkHAu3/Uy2oMyAUQG5QNAwrlvTp48Loc+b+7Sofp2q+MACYfyASDhpHmTdO+sXEnc8wOwAuUDQEIK7nrZvK+eqRcgyigfABLSvbNyleJ26uyFi9p7+rzVcYCEQvkAkJC8SU4tn5sviSfdAtFG+QCQsIK7XjbX1KvfH7A4DZA4KB8AEtaXZ+QoMzlJLZ0+fXTinNVxgIRB+QCQsNwuh8rnFUiSNlaz6wWIFsoHgIRWUTpQPrYcqFdvP1MvQDRQPgAktNumZSs3zaP2nn7tPNpsdRwgIVA+ACQ0p8PQqpKBqx+baph6AaKB8gEg4QV3vWw71KiLvX6L0wDxj/IBIOEtKMpUUdYEdff6tf3TRqvjAHGP8gEg4RmGoYqSS0+6ZdcLEHGUDwDQF896qTrSrPaePovTAPGN8gEAkmblp2lGbqp6/QFtPdBgdRwgrlE+AEADUy/BhaebanjWCxBJlA8AuCQ49fL+sRa1dvosTgPEL8oHAFwyLSdF82/IkD9g6nWmXoCIoXwAwGWCt1vftI9dL0CkUD4A4DKrL225/fjkOdW3XbQ4DRCfKB8AcJnCzAlaOHWiTFN6jYWnQERQPgDgCsFdLxuZegEigvIBAFcon18gp8NQzZk2nWzpsjoOEHcoHwBwhZxUj+68KVsSC0+BSKB8AMAwKgZvOEb5AMKN8gEAw1gxN19up0NHGzv1aUO71XGAuEL5AIBhZExI0j3FkyQx9QKEG+UDAEYw+KyXffUyTdPiNED8oHwAwAiWzs7VhCSnTp/r1r4zbVbHAeIG5QMARpDsdum+OXmSpI3VTL0A4UL5AIBRBHe9bK6pkz/A1AsQDpQPABjF3TNzlO51qanDp9+fOGd1HCAuUD4AYBQel1Mr5+VL4p4fQLhQPgBgDJWlN0iStuyvV58/YHEawP4oHwAwhtunZykn1a3z3X1671iL1XEA26N8AMAYXE6HVs0vkCRtYtcLcN0oHwAwDsFdL28ealRPn9/iNIC9UT4AYBxumTJRN2ROUKevX+982mR1HMDWKB8AMA4Oh6HVJZemXtj1AlwXygcAjFNw6mX74SZ19PRZnAawL8oHAIzT3MJ0Tc9Jka8/oLcON1odB7AtygcAjJNhGINXP3jWC3DtKB8AEIJg+Xj3sxad7+q1OA1gT5QPAAjBjNxUzSlIV3/A1JYDDVbHAWyJ8gEAIQpe/di0j6kX4FpQPgAgRMEtt7tOtKqxvcfiNID9UD4AIERFWcm6ZUqmTFN6rabe6jiA7YRcPnbu3KmKigoVFhbKMAxt2LBhxGO//e1vyzAM/fM///N1RASA2FMZ3PXC1AsQspDLR1dXl0pLS7V+/fpRj3v11Ve1a9cuFRYWXnM4AIhV95cUyGFI1bUXVHuu2+o4gK2EXD7Ky8v1d3/3d3rooYdGPObs2bP6y7/8S/3mN79RUlLSdQUEgFiUm+bVHTdlS+LqBxCqsK/5CAQCWrNmjZ588knNnTt3zON9Pp/a29uHvADADipK2PUCXIuwl4/nnntOLpdLf/VXfzWu49etW6eMjIzBV1FRUbgjAUBErJyXrySnoU8bOvRZY4fVcQDbCGv52LNnj37605/q5ZdflmEY43rPU089pba2tsFXbW1tOCMBQMRkJrt1982TJHH1AwhFWMvHu+++q6amJk2ZMkUul0sul0unTp3S3/zN32jq1KnDvsfj8Sg9PX3ICwDsonLBF7teTNO0OA1gD65w/rA1a9Zo2bJlQ762YsUKrVmzRt/4xjfC+VcBQExYNjtP3iSHTrZ268DZds2fnGF1JCDmhVw+Ojs7dezYscE/nzhxQtXV1crKytKUKVOUnZ095PikpCTl5+eruLj4+tMCQIxJ8bi0dHaeXqup18Z9ZykfwDiEPO2ye/dulZWVqaysTJL0xBNPqKysTE8//XTYwwGAHQR3vWyuqVcgwNQLMJaQr3wsXrw4pHnNkydPhvpXAICtLC6epDSPS/VtPdp96rwWTcuyOhIQ03i2CwBcJ2+SU8vn5kti1wswHpQPAAiD4K6X1/fXq98fsDgNENsoHwAQBnfelK2sFLdau3r1wfFWq+MAMY3yAQBhkOR06P75A1MvPOsFGB3lAwDCJLjrZeuBBvn6/RanAWIX5QMAwmTh1Czlp3vV4etX1ZFmq+MAMYvyAQBh4nAYWl1SIIldL8BoKB8AEEbBXS/bDzepu7ff4jRAbKJ8AEAYzb8hQzdmJ+tin1/bDjVaHQeISZQPAAgjwzBUWTpw9WPTvnqL0wCxifIBAGFWcal87DjapLbuPovTALGH8gEAYTYzL02z8tPU5ze19WCD1XGAmEP5AIAICF794IZjwNUoHwAQAcEbjn1wvEXNHT6L0wCxhfIBABEwJTtZpUWZCpgDD5sD8AXKBwBEyBe7Xph6AS5H+QCACFk1v0CGIe0+dV5nL1y0Og4QMygfABAh+RleLZqaJUnazNUPYBDlAwAiKHi7dXa9AF+gfABABJXPK5DLYehgXbuON3daHQeICZQPAIigrBS37ro5RxILT4EgygcARFjwnh+b9tXJNE2L0wDWo3wAQIQtn5snt8uh481dOlTfbnUcwHKUDwCIsDRvku4tzpXEk24BifIBAFER3PXC1AtA+QCAqLh3Vq5S3E6dvXBRe09fsDoOYCnKBwBEgTfJqeVz8yWx6wWgfABAlFSUFkiSNtfUyx9g6gWJi/IBAFFy14xJykxOUkunT7s+b7U6DmAZygcARInb5VD5PKZeAMoHAERRRenArpctBxrU2x+wOA1gDcoHAETRbdOylZvmUdvFPr37WbPVcQBLUD4AIIqcDkOrSgYWnvKkWyQqygcARFlw6mXboUZd7PVbnAaIPsoHAERZWVGmJk+coO5ev7Z/2mh1HCDqKB8AEGWGYQxe/WDXCxIR5QMALFB5qXy8c6RZ7T19FqcBoovyAQAWmJWfphm5qertD+jNg0y9ILFQPgDAAoZhDF79YNcLEg3lAwAsElz38f6xFrV2+ixOA0QP5QMALDItJ0Xzb8iQP2Dq9QMNVscBoobyAQAWCj7pll0vSCSUDwCw0OqSgamXj0+eU33bRYvTANFB+QAACxVmTtDCqRNlmtJrNfVWxwGigvIBABZj1wsSDeUDACxWPr9AToehmjNtOtnSZXUcIOIoHwBgsZxUj+68KVsSC0+RGCgfABADBp/1UkP5QPyjfABADFgxN19up0NHGzv1aUO71XGAiKJ8AEAMyJiQpHuKJ0li6gXxj/IBADEiuOtl0756maZpcRogcigfABAjls7O1YQkp06f69a+M21WxwEihvIBADEi2e3SfXPyJDH1gvhG+QCAGBLc9bK5pk7+AFMviE+UDwCIIXfPzFG616XGdp8+PnnO6jhARFA+ACCGeFxOrZyXL4nbrSN+UT4AIMZUlt4gSdqyv159/oDFaYDwo3wAQIy5fXqWclLdOt/dp/eOtVgdBwg7ygcAxBiX06FV8wsksesF8YnyAQAxKLjr5c2Djerp81ucBggvygcAxKBbpkzUDZkT1OnrV9WRJqvjAGEVcvnYuXOnKioqVFhYKMMwtGHDhiHf/9GPfqRZs2YpJSVFEydO1LJly/TRRx+FKy8AJASHw9DqkoGpF3a9IN6EXD66urpUWlqq9evXD/v9mTNn6oUXXtD+/fv13nvvaerUqVq+fLmam5uvOywAJJLg1Mv2w03q9PVbnAYIH8O8jqcXGYahV199VQ8++OCIx7S3tysjI0NvvfWWli5dOubPDB7f1tam9PT0a40GALZnmqaW/uMOfd7Spee/UqqHyiZbHQkYUSi/vyO65qO3t1e//OUvlZGRodLS0mGP8fl8am9vH/ICAAz8D17FZU+6BeJFRMrH5s2blZqaKq/Xq+eff17btm1TTk7OsMeuW7dOGRkZg6+ioqJIRAIAWwqWj51Hm3W+q9fiNEB4RKR8LFmyRNXV1frggw+0cuVKPfzww2pqGn619lNPPaW2trbBV21tbSQiAYAtzchN1ZyCdPUHTL1xsMHqOEBYRKR8pKSkaMaMGbr99tv1q1/9Si6XS7/61a+GPdbj8Sg9PX3ICwDwheDVj43V7HpBfIjKfT4CgYB8Pl80/ioAiDvBLbe7TrSqqb3H4jTA9Qu5fHR2dqq6ulrV1dWSpBMnTqi6ulqnT59WV1eX/vZv/1a7du3SqVOntGfPHn3zm9/U2bNn9cd//Mfhzg4ACaEoK1m3TMmUaUqba1h4CvsLuXzs3r1bZWVlKisrkyQ98cQTKisr09NPPy2n06lPP/1Uf/iHf6iZM2eqoqJCra2tevfddzV37tywhweARFEZ3PVSw9QL7O+67vMRCdznAwCu1tTRo9v/33YFTOnd7y1RUVay1ZGAIWLmPh8AgPDITfPqjpuyJXH1A/ZH+QAAm6goYdcL4gPlAwBsYuW8fCU5DX3a0KHPGjusjgNcM8oHANhEZrJbd988SZK0iSfdwsYoHwBgI5ULgrte6hVj+wWAcaN8AICNLJudJ2+SQydaunTgLA/ihD1RPgDARlI8Li2dlSeJXS+wL8oHANhM8Fkvm/bVKRBg6gX2Q/kAAJtZXDxJaR6X6tt6tOf0eavjACGjfACAzXiTnFo+N18S9/yAPVE+AMCGKkoHnnT7+v569fsDFqcBQkP5AAAb+vKMHGWluNXa1asPjrdaHQcICeUDAGwoyelQ+byBqRduOAa7oXwAgE1VXtr18sbBBvn6/RanAcaP8gEANrVwapby073q6OnXjiPNVscBxo3yAQA25XAYWl0ysPB0I1MvsBHKBwDYWPCGY9sPN6m7t9/iNMD4UD4AwMZKJmfoxuxkXezza9uhRqvjAONC+QAAGzMMQxUlwdut11ucBhgfygcA2FzlgoHyseNok9q6+yxOA4yN8gEANjczL03FeWnq85vaerDB6jjAmCgfABAHglc/2PUCO6B8AEAcCG65/eB4i5o7fBanAUZH+QCAOHBjdopKizIVMAceNgfEMsoHAMSJiktXP3jWC2Id5QMA4sTqkkIZhrT71HmdvXDR6jjAiCgfABAn8jO8WjQ1S5K0masfiGGUDwCII8FdL5tqKB+IXZQPAIgj5fMK5HIYOnC2XZ83d1odBxgW5QMA4khWilt33ZwjidutI3ZRPgAgzgSf9bJx31mZpmlxGuBqlA8AiDPL5+bJ7XLoeHOXDtd3WB0HuArlAwDiTJo3SfcW50riduuITZQPAIhDg7te9tUx9YKYQ/kAgDh076xcpbidOnvhovaevmB1HGAIygcAxCFvklPL5+ZL4nbriD2UDwCIUxWlA896eW1/vfwBpl4QOygfABCn7poxSZnJSWru8Omjz1utjgMMonwAQJxyuxwqnzcw9cKuF8QSygcAxLGK0oFdL1sONKi3P2BxGmAA5QMA4tht07KVm+ZR28U+vftZs9VxAEmUDwCIa06HoVUlAwtP2fWCWEH5AIA4F5x6efNQoy72+i1OA1A+ACDulRVlavLECeru9evtT5usjgNQPgAg3hmGMXj1Y+O+sxanASgfAJAQKi+Vj3eONKu9p8/iNEh0lA8ASACz8tM0IzdVvf0BvXmw0eo4SHCUDwBIAIZhDF79YNcLrEb5AIAEEVz38d6xFrV2+ixOg0RG+QCABDEtJ0Xzb8iQP2Bqy4EGq+MggVE+ACCBBJ90y7NeYCXKBwAkkNUlA1MvH588p/q2ixanQaKifABAAinMnKCFUyfKNKXXauqtjoMERfkAgATDrhdYjfIBAAmmfH6BnA5D+8606WRLl9VxkIAoHwCQYHJSPbrzpmxJ0uYarn4g+igfAJCAvnjWC+UD0Uf5AIAEtGJuvtxOh442dupIQ4fVcZBgKB8AkIAyJiTpnuJJknjSLaKP8gEACeqLXS/1Mk3T4jRIJJQPAEhQS2fnakKSU6fPdWvfmTar4yCBUD4AIEElu126b06eJO75gegKuXzs3LlTFRUVKiwslGEY2rBhw+D3+vr69P3vf1/z589XSkqKCgsL9ad/+qeqq+M/agCIRcFdL5tr6uQPMPWC6Ai5fHR1dam0tFTr16+/6nvd3d3au3evfvjDH2rv3r36n//5Hx05ckSVlZVhCQsACK+7Z+Yo3etSY7tPH588Z3UcJAhXqG8oLy9XeXn5sN/LyMjQtm3bhnzthRde0KJFi3T69GlNmTLl2lICACLC43Jq5bx8/Xb3GW3cV6fbp2dbHQkJIOJrPtra2mQYhjIzM4f9vs/nU3t7+5AXACB6KktvkCRt2V+vPn/A4jRIBBEtHz09Pfr+97+vr33ta0pPTx/2mHXr1ikjI2PwVVRUFMlIAIAr3D49Szmpbp3v7tN7x1qsjoMEELHy0dfXp4cfflimaernP//5iMc99dRTamtrG3zV1tZGKhIAYBgup0P3zy+QxK4XREdEykeweJw6dUrbtm0b8aqHJHk8HqWnpw95AQCiK3jDsTcPNqqnz29xGsS7sJePYPH47LPP9NZbbyk7m8VLABDrbpkyUYUZXnX6+lV1pMnqOIhzIZePzs5OVVdXq7q6WpJ04sQJVVdX6/Tp0+rr69Mf/dEfaffu3frNb34jv9+vhoYGNTQ0qLe3N9zZAQBh4nAYPOkWUWOYId7Qv6qqSkuWLLnq64888oh+9KMfadq0acO+75133tHixYvH/Pnt7e3KyMhQW1sbUzAAEEUHzrZp9c/ek8fl0J4f3qdUT8h3Y0ACC+X3d8j/ZS1evHjUBxDxcCIAsKe5hemanpOiz1u6tO1Qgx4qm2x1JMQpnu0CAJAkGYah1Zc96RaIFMoHAGBQZenAltudR5t1oZu1eogMygcAYNCM3DTNLkhXf8DUlgMNVsdBnKJ8AACGqBycemHXCyKD8gEAGGJ1ycDUy4eft6qpvcfiNIhHlA8AwBBFWcm6ZUqmTFN6bT8LTxF+lA8AwFW44RgiifIBALjKqpICOQzpk9MXVHuu2+o4iDOUDwDAVXLTvLp9+sCzuTbVcPUD4UX5AAAMq5IbjiFCKB8AgGGtnJevJKehw/XtOtbUYXUcxBHKBwBgWJnJbt198yRJ0kaufiCMKB8AgBFVXHbDMR4cinChfAAARnTfnDx5kxw60dKlg3XtVsdBnKB8AABGlOJxaemsPEnc8wPhQ/kAAIwqOPWyeV+dAgGmXnD9KB8AgFEtLp6kNI9LdW092nP6vNVxEAcoHwCAUXmTnFo+N18ST7pFeFA+AABjqigdeNLt6/vr1e8PWJwGdkf5AACM6cszcpSV4lZLZ68+/LzV6jiwOcoHAGBMSU6HyucNTL1srGbqBdfHZXUAAIA9VJYW6jcfndYbBxqU6uXXh525HIZ+sGqOdX+/ZX8zAMBWFk7NUmGGV3VtPXrp/ZNWx8F1cLsclA8AQOxzOAy9uOZL2nqwQaa434edOR3WrrqgfAAAxm3+5AzNn5xhdQzYHAtOAQBAVFE+AABAVFE+AABAVFE+AABAVFE+AABAVFE+AABAVFE+AABAVFE+AABAVFE+AABAVFE+AABAVFE+AABAVFE+AABAVFE+AABAVMXcU21Nc+Axze3t7RYnAQAA4xX8vR38PT6amCsfHR0dkqSioiKLkwAAgFB1dHQoIyNj1GMMczwVJYoCgYDq6uqUlpYmwzDC+rPb29tVVFSk2tpapaenh/Vnx4J4H58U/2NkfPYX72OM9/FJ8T/GSI3PNE11dHSosLBQDsfoqzpi7sqHw+HQ5MmTI/p3pKenx+V/UEHxPj4p/sfI+Owv3scY7+OT4n+MkRjfWFc8glhwCgAAooryAQAAoiqhyofH49Ezzzwjj8djdZSIiPfxSfE/RsZnf/E+xngfnxT/Y4yF8cXcglMAABDfEurKBwAAsB7lAwAARBXlAwAARBXlAwAARFXclY/169dr6tSp8nq9uu222/T73/9+1OP/67/+S7NmzZLX69X8+fP1+uuvRynptQllfC+//LIMwxjy8nq9UUwbmp07d6qiokKFhYUyDEMbNmwY8z1VVVW65ZZb5PF4NGPGDL388ssRz3k9Qh1jVVXVVefQMAw1NDREJ3CI1q1bp4ULFyotLU25ubl68MEHdeTIkTHfZ5fP4bWMz06fw5///OcqKSkZvPnUHXfcoS1btoz6Hrucu6BQx2in8zecZ599VoZh6PHHHx/1uGifx7gqH//5n/+pJ554Qs8884z27t2r0tJSrVixQk1NTcMe/8EHH+hrX/uavvWtb+mTTz7Rgw8+qAcffFAHDhyIcvLxCXV80sAd7Orr6wdfp06dimLi0HR1dam0tFTr168f1/EnTpzQqlWrtGTJElVXV+vxxx/Xn/3Zn2nr1q0RTnrtQh1j0JEjR4acx9zc3AglvD47duzQo48+ql27dmnbtm3q6+vT8uXL1dXVNeJ77PQ5vJbxSfb5HE6ePFnPPvus9uzZo927d+vee+/VAw88oIMHDw57vJ3OXVCoY5Tsc/6u9PHHH+vFF19USUnJqMdZch7NOLJo0SLz0UcfHfyz3+83CwsLzXXr1g17/MMPP2yuWrVqyNduu+028y/+4i8imvNahTq+l156yczIyIhSuvCSZL766qujHvO9733PnDt37pCvfeUrXzFXrFgRwWThM54xvvPOO6Yk8/z581HJFG5NTU2mJHPHjh0jHmO3z+HlxjM+O38OTdM0J06caP7Lv/zLsN+z87m73GhjtOv56+joMG+++WZz27Zt5j333GM+9thjIx5rxXmMmysfvb292rNnj5YtWzb4NYfDoWXLlunDDz8c9j0ffvjhkOMlacWKFSMeb6VrGZ8kdXZ26sYbb1RRUdGY7d5u7HT+rteCBQtUUFCg++67T++//77Vccatra1NkpSVlTXiMXY+j+MZn2TPz6Hf79crr7yirq4u3XHHHcMeY+dzJ41vjJI9z9+jjz6qVatWXXV+hmPFeYyb8tHS0iK/36+8vLwhX8/LyxtxfryhoSGk4610LeMrLi7Wr3/9a/3v//6v/v3f/12BQEB33nmnzpw5E43IETfS+Wtvb9fFixctShVeBQUF+sUvfqHf/e53+t3vfqeioiItXrxYe/futTramAKBgB5//HF9+ctf1rx580Y8zk6fw8uNd3x2+xzu379fqamp8ng8+va3v61XX31Vc+bMGfZYu567UMZot/MnSa+88or27t2rdevWjet4K85jzD3VFuFzxx13DGnzd955p2bPnq0XX3xRP/nJTyxMhvEqLi5WcXHx4J/vvPNOHT9+XM8//7z+7d/+zcJkY3v00Ud14MABvffee1ZHiYjxjs9un8Pi4mJVV1erra1N//3f/61HHnlEO3bsGPGXsx2FMka7nb/a2lo99thj2rZtW0wvjI2b8pGTkyOn06nGxsYhX29sbFR+fv6w78nPzw/peCtdy/iulJSUpLKyMh07diwSEaNupPOXnp6uCRMmWJQq8hYtWhTzv9C/+93vavPmzdq5c6cmT5486rF2+hwGhTK+K8X659DtdmvGjBmSpFtvvVUff/yxfvrTn+rFF1+86lg7njsptDFeKdbP3549e9TU1KRbbrll8Gt+v187d+7UCy+8IJ/PJ6fTOeQ9VpzHuJl2cbvduvXWW7V9+/bBrwUCAW3fvn3Eubw77rhjyPGStG3btlHn/qxyLeO7kt/v1/79+1VQUBCpmFFlp/MXTtXV1TF7Dk3T1He/+129+uqrevvttzVt2rQx32On83gt47uS3T6HgUBAPp9v2O/Z6dyNZrQxXinWz9/SpUu1f/9+VVdXD76+9KUv6U/+5E9UXV19VfGQLDqPEVvKaoFXXnnF9Hg85ssvv2weOnTI/PM//3MzMzPTbGhoME3TNNesWWOuXbt28Pj333/fdLlc5j/8wz+Yhw8fNp955hkzKSnJ3L9/v1VDGFWo4/vxj39sbt261Tx+/Li5Z88e86tf/arp9XrNgwcPWjWEUXV0dJiffPKJ+cknn5iSzH/6p38yP/nkE/PUqVOmaZrm2rVrzTVr1gwe//nnn5vJycnmk08+aR4+fNhcv3696XQ6zTfeeMOqIYwp1DE+//zz5oYNG8zPPvvM3L9/v/nYY4+ZDofDfOutt6wawqi+853vmBkZGWZVVZVZX18/+Oru7h48xs6fw2sZn50+h2vXrjV37NhhnjhxwqypqTHXrl1rGoZhvvnmm6Zp2vvcBYU6Rjudv5FcudslFs5jXJUP0zTNn/3sZ+aUKVNMt9ttLlq0yNy1a9fg9+655x7zkUceGXL8b3/7W3PmzJmm2+02586da7722mtRThyaUMb3+OOPDx6bl5dn3n///ebevXstSD0+wW2lV76CY3rkkUfMe+6556r3LFiwwHS73eb06dPNl156Keq5QxHqGJ977jnzpptuMr1er5mVlWUuXrzYfPvtt60JPw7DjU3SkPNi58/htYzPTp/Db37zm+aNN95out1uc9KkSebSpUsHfymbpr3PXVCoY7TT+RvJleUjFs6jYZqmGbnrKgAAAEPFzZoPAABgD5QPAAAQVZQPAAAQVZQPAAAQVZQPAAAQVZQPAAAQVZQPAAAQVZQPAAAQVZQPAAAQVZQPAAAQVZQPAAAQVZQPAAAQVf8f37kTWdwnxCIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
